<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"flat"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="第四章：底层：训练数字分类器在第二章中看到训练各种模型的样子后，现在让我们深入了解并看看究竟发生了什么。我们将使用计算机视觉来介绍深度学习的基本工具和概念。 确切地说，我们将讨论数组和张量的作用以及广播的作用，这是一种使用它们表达性地的强大技术。我们将解释随机梯度下降（SGD），这是通过自动更新权重学习的机制。我们将讨论基本分类任务的损失函数的选择，以及小批量的作用。我们还将描述基本神经网络正在执">
<meta property="og:type" content="article">
<meta property="og:title" content="Fastai Chapter 4">
<meta property="og:url" content="http://example.com/2025/04/28/fastaichapter4/index.html">
<meta property="og:site_name" content="WangSong&#39;s blog">
<meta property="og:description" content="第四章：底层：训练数字分类器在第二章中看到训练各种模型的样子后，现在让我们深入了解并看看究竟发生了什么。我们将使用计算机视觉来介绍深度学习的基本工具和概念。 确切地说，我们将讨论数组和张量的作用以及广播的作用，这是一种使用它们表达性地的强大技术。我们将解释随机梯度下降（SGD），这是通过自动更新权重学习的机制。我们将讨论基本分类任务的损失函数的选择，以及小批量的作用。我们还将描述基本神经网络正在执">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/image/dlcf_04in01.png">
<meta property="og:image" content="http://example.com/image/dlcf_04in02.png">
<meta property="og:image" content="http://example.com/image/dlcf_04in03.png">
<meta property="og:image" content="http://example.com/image/dlcf_04in04.png">
<meta property="og:image" content="http://example.com/image/dlcf_04in05.png">
<meta property="og:image" content="http://example.com/image/dlcf_04in06.png">
<meta property="og:image" content="http://example.com/image/dlcf_0401.png">
<meta property="og:image" content="http://example.com/image/dlcf_04in07.png">
<meta property="og:image" content="http://example.com/image/dlcf_04in08.png">
<meta property="og:image" content="http://example.com/image/dlcf_04in09.png">
<meta property="og:image" content="http://example.com/image/dlcf_04in10.png">
<meta property="article:published_time" content="2025-04-28T01:30:20.000Z">
<meta property="article:modified_time" content="2025-04-29T08:03:27.235Z">
<meta property="article:author" content="Wang Song">
<meta property="article:tag" content="Python, C++, robot, ros , opencv, target detection">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/image/dlcf_04in01.png">

<link rel="canonical" href="http://example.com/2025/04/28/fastaichapter4/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Fastai Chapter 4 | WangSong's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="WangSong's blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WangSong's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/SongSop" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/28/fastaichapter4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wang Song">
      <meta itemprop="description" content="a graduate student working at Huzhou institute of Zhejiang University">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WangSong's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Fastai Chapter 4
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-04-28 09:30:20" itemprop="dateCreated datePublished" datetime="2025-04-28T09:30:20+08:00">2025-04-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-04-29 16:03:27" itemprop="dateModified" datetime="2025-04-29T16:03:27+08:00">2025-04-29</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="第四章：底层：训练数字分类器"><a href="#第四章：底层：训练数字分类器" class="headerlink" title="第四章：底层：训练数字分类器"></a>第四章：底层：训练数字分类器</h1><p>在第二章中看到训练各种模型的样子后，现在让我们深入了解并看看究竟发生了什么。我们将使用计算机视觉来介绍深度学习的基本工具和概念。</p>
<p>确切地说，我们将讨论数组和张量的作用以及广播的作用，这是一种使用它们表达性地的强大技术。我们将解释随机梯度下降（SGD），这是通过自动更新权重学习的机制。我们将讨论基本分类任务的损失函数的选择，以及小批量的作用。我们还将描述基本神经网络正在执行的数学。最后，我们将把所有这些部分组合起来。</p>
<p>在未来的章节中，我们还将深入研究其他应用，并看看这些概念和工具如何泛化。但本章是关于奠定基础的。坦率地说，这也使得这是最困难的章节之一，因为这些概念彼此相互依赖。就像一个拱门，所有的石头都需要放在正确的位置才能支撑结构。也像一个拱门，一旦发生这种情况，它就是一个强大的结构，可以支撑其他事物。但是需要一些耐心来组装。</p>
<p>让我们开始吧。第一步是考虑图像在计算机中是如何表示的。</p>
<h1 id="像素：计算机视觉的基础"><a href="#像素：计算机视觉的基础" class="headerlink" title="像素：计算机视觉的基础"></a>像素：计算机视觉的基础</h1><p>要理解计算机视觉模型中发生的事情，我们首先必须了解计算机如何处理图像。我们将使用计算机视觉中最著名的数据集之一 MNIST 进行实验。MNIST 包含由国家标准与技术研究所收集的手写数字图像，并由 Yann Lecun 及其同事整理成一个机器学习数据集。Lecun 在 1998 年使用 MNIST 在 LeNet-5 中，这是第一个演示实用手写数字序列识别的计算机系统。这是人工智能历史上最重要的突破之一。</p>
<p>对于这个初始教程，我们只是尝试创建一个模型，可以将任何图像分类为 3 或 7。所以让我们下载一个包含这些数字图像的 MNIST 样本：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">path = untar_data(URLs.MNIST_SAMPLE)</span><br></pre></td></tr></table></figure>
<p>我们可以使用<code>ls</code>来查看此目录中的内容，这是 fastai 添加的一个方法。这个方法返回一个特殊的 fastai 类<code>L</code>的对象，它具有 Python 内置<code>list</code>的所有功能，还有更多功能。其中一个方便的功能是，在打印时，它会显示项目的计数，然后列出项目本身（如果项目超过 10 个，它只显示前几个）：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">path.ls()</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(<span class="comment">#9) [Path(&#x27;cleaned.csv&#x27;),Path(&#x27;item_list.txt&#x27;),Path(&#x27;trained_model.pkl&#x27;),Path(&#x27;</span></span><br><span class="line"> &gt; models<span class="string">&#x27;),Path(&#x27;</span>valid<span class="string">&#x27;),Path(&#x27;</span>labels.csv<span class="string">&#x27;),Path(&#x27;</span>export.pkl<span class="string">&#x27;),Path(&#x27;</span>history.cs</span><br><span class="line"> &gt; v<span class="string">&#x27;),Path(&#x27;</span>train<span class="string">&#x27;)]</span></span><br></pre></td></tr></table></figure>
<p>MNIST 数据集遵循机器学习数据集的常见布局：训练集和验证（和/或测试）集分开存放。让我们看看训练集中的内容：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(path/<span class="string">&#x27;train&#x27;</span>).ls()</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="comment">#2) [Path(&#x27;train/7&#x27;),Path(&#x27;train/3&#x27;)]</span></span><br></pre></td></tr></table></figure>
<p>有一个包含 3 的文件夹，和一个包含 7 的文件夹。在机器学习术语中，我们说“3”和“7”是这个数据集中的<em>标签</em>（或目标）。让我们看看其中一个文件夹中的内容（使用<code>sorted</code>确保我们都得到相同的文件顺序）：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">threes = (path/<span class="string">&#x27;train&#x27;</span>/<span class="string">&#x27;3&#x27;</span>).ls().<span class="built_in">sorted</span>()</span><br><span class="line">sevens = (path/<span class="string">&#x27;train&#x27;</span>/<span class="string">&#x27;7&#x27;</span>).ls().<span class="built_in">sorted</span>()</span><br><span class="line">threes</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(<span class="comment">#6131) [Path(&#x27;train/3/10.png&#x27;),Path(&#x27;train/3/10000.png&#x27;),Path(&#x27;train/3/10011.pn</span></span><br><span class="line"> &gt; g<span class="string">&#x27;),Path(&#x27;</span>train/<span class="number">3</span>/<span class="number">10031.</span>png<span class="string">&#x27;),Path(&#x27;</span>train/<span class="number">3</span>/<span class="number">10034.</span>png<span class="string">&#x27;),Path(&#x27;</span>train/<span class="number">3</span>/<span class="number">10042.</span>p</span><br><span class="line"> &gt; ng<span class="string">&#x27;),Path(&#x27;</span>train/<span class="number">3</span>/<span class="number">10052.</span>png<span class="string">&#x27;),Path(&#x27;</span>train/<span class="number">3</span>/<span class="number">1007.</span>png<span class="string">&#x27;),Path(&#x27;</span>train/<span class="number">3</span>/<span class="number">10074.</span>p</span><br><span class="line"> &gt; ng<span class="string">&#x27;),Path(&#x27;</span>train/<span class="number">3</span>/<span class="number">10091.</span>png<span class="string">&#x27;)...]</span></span><br></pre></td></tr></table></figure>
<p>正如我们所预期的那样，它充满了图像文件。让我们现在看一个。这是一个手写数字 3 的图像，来自著名的手写数字 MNIST 数据集：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">im3_path = threes[<span class="number">1</span>]</span><br><span class="line">im3 = Image.<span class="built_in">open</span>(im3_path)</span><br><span class="line">im3</span><br></pre></td></tr></table></figure>
<p><img src="/image/dlcf_04in01.png" alt=""></p>
<p>在这里，我们使用<em>Python Imaging Library</em>（PIL）中的<code>Image</code>类，这是最广泛使用的 Python 包，用于打开、操作和查看图像。Jupyter 知道 PIL 图像，所以它会自动为我们显示图像。</p>
<p>在计算机中，一切都以数字表示。要查看构成这幅图像的数字，我们必须将其转换为<em>NumPy 数组</em>或<em>PyTorch 张量</em>。例如，这是转换为 NumPy 数组后图像的一部分的样子：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array(im3)[<span class="number">4</span>:<span class="number">10</span>,<span class="number">4</span>:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">array([[  <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>],</span><br><span class="line">       [  <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,  <span class="number">29</span>],</span><br><span class="line">       [  <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,  <span class="number">48</span>, <span class="number">166</span>, <span class="number">224</span>],</span><br><span class="line">       [  <span class="number">0</span>,  <span class="number">93</span>, <span class="number">244</span>, <span class="number">249</span>, <span class="number">253</span>, <span class="number">187</span>],</span><br><span class="line">       [  <span class="number">0</span>, <span class="number">107</span>, <span class="number">253</span>, <span class="number">253</span>, <span class="number">230</span>,  <span class="number">48</span>],</span><br><span class="line">       [  <span class="number">0</span>,   <span class="number">3</span>,  <span class="number">20</span>,  <span class="number">20</span>,  <span class="number">15</span>,   <span class="number">0</span>]], dtype=uint8)</span><br></pre></td></tr></table></figure>
<p><code>4:10</code>表示我们请求从索引 4（包括）到 10（不包括）的行，列也是一样。NumPy 从上到下，从左到右索引，因此此部分位于图像的左上角附近。这里是一个 PyTorch 张量：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(im3)[<span class="number">4</span>:<span class="number">10</span>,<span class="number">4</span>:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tensor([[  <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>],</span><br><span class="line">        [  <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,  <span class="number">29</span>],</span><br><span class="line">        [  <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,  <span class="number">48</span>, <span class="number">166</span>, <span class="number">224</span>],</span><br><span class="line">        [  <span class="number">0</span>,  <span class="number">93</span>, <span class="number">244</span>, <span class="number">249</span>, <span class="number">253</span>, <span class="number">187</span>],</span><br><span class="line">        [  <span class="number">0</span>, <span class="number">107</span>, <span class="number">253</span>, <span class="number">253</span>, <span class="number">230</span>,  <span class="number">48</span>],</span><br><span class="line">        [  <span class="number">0</span>,   <span class="number">3</span>,  <span class="number">20</span>,  <span class="number">20</span>,  <span class="number">15</span>,   <span class="number">0</span>]], dtype=torch.uint8)</span><br></pre></td></tr></table></figure>
<p><code>4:10</code>表示我们请求从索引 4（包括）到 10（不包括）的行，列也是一样。NumPy 从上到下，从左到右索引，因此此部分位于图像的左上角附近。这里是一个 PyTorch 张量：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(im3)[<span class="number">4</span>:<span class="number">10</span>,<span class="number">4</span>:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tensor([[  <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>],</span><br><span class="line">        [  <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,  <span class="number">29</span>],</span><br><span class="line">        [  <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,  <span class="number">48</span>, <span class="number">166</span>, <span class="number">224</span>],</span><br><span class="line">        [  <span class="number">0</span>,  <span class="number">93</span>, <span class="number">244</span>, <span class="number">249</span>, <span class="number">253</span>, <span class="number">187</span>],</span><br><span class="line">        [  <span class="number">0</span>, <span class="number">107</span>, <span class="number">253</span>, <span class="number">253</span>, <span class="number">230</span>,  <span class="number">48</span>],</span><br><span class="line">        [  <span class="number">0</span>,   <span class="number">3</span>,  <span class="number">20</span>,  <span class="number">20</span>,  <span class="number">15</span>,   <span class="number">0</span>]], dtype=torch.uint8)</span><br></pre></td></tr></table></figure>
<p>我们可以切片数组，只选择包含数字顶部部分的部分，然后使用 Pandas DataFrame 使用渐变对值进行着色，这清楚地显示了图像是如何由像素值创建的：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">im3_t = tensor(im3)</span><br><span class="line">df = pd.DataFrame(im3_t[<span class="number">4</span>:<span class="number">15</span>,<span class="number">4</span>:<span class="number">22</span>])</span><br><span class="line">df.style.set_properties(**&#123;<span class="string">&#x27;font-size&#x27;</span>:<span class="string">&#x27;6pt&#x27;</span>&#125;).background_gradient(<span class="string">&#x27;Greys&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/image/dlcf_04in02.png" alt=""></p>
<p>你可以看到，背景白色像素存储为数字 0，黑色为数字 255，灰色在两者之间。整个图像横向包含 28 个像素，纵向包含 28 个像素，总共 768 个像素。（这比你从手机相机得到的图像要小得多，手机相机有数百万像素，但对于我们的初始学习和实验来说，这是一个方便的大小。我们将很快构建更大的全彩图像。）</p>
<p>所以，现在你已经看到了计算机对图像的看法，让我们回顾一下我们的目标：创建一个能够识别 3 和 7 的模型。你会如何让计算机做到这一点呢？</p>
<h1 id="停下来思考！"><a href="#停下来思考！" class="headerlink" title="停下来思考！"></a>停下来思考！</h1><p>在继续阅读之前，花点时间考虑一下计算机可能如何识别这两个数字。它可能能够看到什么样的特征？它可能如何识别这些特征？它如何将它们结合起来？学习最好的方式是尝试自己解决问题，而不仅仅是阅读别人的答案；所以离开这本书几分钟，拿一张纸和笔，写下一些想法。</p>
<font color = red> 我认为计算机可能会用识别到的手写数字图像的矩阵和标准的数字图像的矩阵进行运算像是点乘或是什么得出一个能给表现图片数字和标准数字相似度的一个数值进行比较取得最大的为识别数字。</font>

<h1 id="第一次尝试：像素相似度"><a href="#第一次尝试：像素相似度" class="headerlink" title="第一次尝试：像素相似度"></a>第一次尝试：像素相似度</h1><p>所以，这是一个第一个想法：我们可以找到每个 3 的像素的平均值，然后对 7 做同样的操作。这将给我们两组平均值，定义了我们可能称之为“理想”3 和 7。然后，为了将图像分类为一个数字或另一个数字，我们看看这两个理想数字中图像与哪个更相似。这肯定似乎比没有好，所以这将成为一个很好的基线。</p>
<h1 id="术语：基线"><a href="#术语：基线" class="headerlink" title="术语：基线"></a>术语：基线</h1><p>一个简单的模型，你有信心应该表现得相当不错。它应该简单实现和易于测试，这样你就可以测试每个改进的想法，并确保它们始终优于基线。如果没有以合理的基线开始，很难知道你的超级花哨的模型是否好用。创建基线的一个好方法是做我们在这里做的事情：考虑一个简单、易于实现的模型。另一个好方法是四处寻找解决类似问题的其他人，并在你的数据集上下载并运行他们的代码。最好两者都尝试一下！</p>
<p>我们简单模型的第一步是获取我们两组像素值的平均值。在这个过程中，我们将学习很多有趣的 Python 数值编程技巧！</p>
<p>让我们创建一个包含所有 3 的张量堆叠在一起。我们已经知道如何创建包含单个图像的张量。要创建一个包含目录中所有图像的张量，我们将首先使用 Python 列表推导来创建一个单个图像张量的普通列表。</p>
<p>我们将使用 Jupyter 在途中做一些小的检查——在这种情况下，确保返回的项目数量看起来合理：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">seven_tensors = [tensor(Image.<span class="built_in">open</span>(o)) <span class="keyword">for</span> o <span class="keyword">in</span> sevens]</span><br><span class="line">three_tensors = [tensor(Image.<span class="built_in">open</span>(o)) <span class="keyword">for</span> o <span class="keyword">in</span> threes]</span><br><span class="line"><span class="built_in">len</span>(three_tensors),<span class="built_in">len</span>(seven_tensors)</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">6131</span>, <span class="number">6265</span>)</span><br></pre></td></tr></table></figure>
<h1 id="列表推导"><a href="#列表推导" class="headerlink" title="列表推导"></a>列表推导</h1><p>列表和字典推导是 Python 的一个很棒的特性。许多 Python 程序员每天都在使用它们，包括本书的作者们——它们是“Python 的成语”。但是来自其他语言的程序员可能以前从未见过它们。许多很棒的教程只需一次网络搜索，所以我们现在不会花很长时间讨论它们。这里有一个快速的解释和示例，让您开始。列表推导看起来像这样：<code>new_list = [f(o) for o in a_list if o&gt;0]</code>。这将返回<code>a_list</code>中大于 0 的每个元素，在将其传递给函数<code>f</code>之后。这里有三个部分：您正在迭代的集合（<code>a_list</code>），一个可选的过滤器（<code>if o&gt;0</code>），以及对每个元素执行的操作（<code>f(o)</code>）。不仅写起来更短，而且比用循环创建相同列表的替代方法更快。</p>
<p>我们还将检查其中一张图像是否正常。由于我们现在有张量（Jupyter 默认会将其打印为值），而不是 PIL 图像（Jupyter 默认会显示图像），我们需要使用 fastai 的<code>show_image</code>函数来显示它：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show_image(three_tensors[<span class="number">1</span>]);</span><br></pre></td></tr></table></figure>
<p><img src="/image/dlcf_04in03.png" alt=""></p>
<p>对于每个像素位置，我们想要计算该像素的强度在所有图像上的平均值。为了做到这一点，我们首先将此列表中的所有图像组合成一个三维张量。描述这样的张量最常见的方式是称之为<em>rank-3 张量</em>。我们经常需要将集合中的单个张量堆叠成一个张量。不出所料，PyTorch 带有一个名为<code>stack</code>的函数，我们可以用它来实现这个目的。</p>
<p>PyTorch 中的一些操作，如取平均值，需要我们将整数类型转换为浮点类型。由于我们稍后会需要这个，我们现在也将我们的堆叠张量转换为<code>float</code>。在 PyTorch 中进行转换就像写下您希望转换为的类型名称，并将其视为方法一样简单。</p>
<p>通常，当图像是浮点数时，像素值应该在 0 到 1 之间，所以我们也会在这里除以 255：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">stacked_sevens = torch.stack(seven_tensors).<span class="built_in">float</span>()/<span class="number">255</span></span><br><span class="line">stacked_threes = torch.stack(three_tensors).<span class="built_in">float</span>()/<span class="number">255</span></span><br><span class="line">stacked_threes.shape</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([<span class="number">6131</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br></pre></td></tr></table></figure>
<p>张量最重要的属性也许是其<em>形状</em>。这告诉您每个轴的长度。在这种情况下，我们可以看到我们有 6,131 张图像，每张图像大小为 28×28 像素。关于这个张量没有特别的地方表明第一个轴是图像的数量，第二个是高度，第三个是宽度——张量的语义完全取决于我们以及我们如何构建它。就 PyTorch 而言，它只是内存中的一堆数字。</p>
<p>张量形状的<em>长度</em>是其秩：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(stacked_threes.shape)</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">3</span></span><br></pre></td></tr></table></figure>
<p>对于您来说，将张量术语的这些部分记忆并加以实践非常重要：<em>秩</em>是张量中轴或维度的数量；<em>形状</em>是张量每个轴的大小。</p>
<h1 id="关于维度"><a href="#关于维度" class="headerlink" title="关于维度"></a>关于维度</h1><p>要小心，因为术语“维度”有时以两种方式使用。考虑我们生活在“三维空间”中，其中物理位置可以用长度为 3 的向量<code>v</code>描述。但根据 PyTorch，属性<code>v.ndim</code>（看起来确实像<code>v</code>的“维度数量”）等于一，而不是三！为什么？因为<code>v</code>是一个向量，它是一个秩为一的张量，这意味着它只有一个<em>轴</em>（即使该轴的长度为三）。换句话说，有时维度用于描述轴的大小（“空间是三维的”），而其他时候用于描述秩或轴的数量（“矩阵有两个维度”）。当感到困惑时，我发现将所有陈述转换为秩、轴和长度这些明确的术语是有帮助的。</p>
<p>我们也可以直接使用<code>ndim</code>来获取张量的秩：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stacked_threes.ndim</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">3</span></span><br></pre></td></tr></table></figure>
<p>最后，我们可以计算理想的 3 是什么样子的。我们通过沿着我们堆叠的 rank-3 张量的维度 0 取平均值来计算所有图像张量的平均值。这是索引所有图像的维度。</p>
<p>换句话说，对于每个像素位置，这将计算所有图像中该像素的平均值。结果将是每个像素位置的一个值，或者一个单独的图像。这就是它：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mean3 = stacked_threes.mean(<span class="number">0</span>)</span><br><span class="line">show_image(mean3);</span><br></pre></td></tr></table></figure>
<p><img src="/image/dlcf_04in04.png" alt=""></p>
<p>根据这个数据集，这是理想的数字 3！（您可能不喜欢，但这就是顶级数字 3 表现的样子。）您可以看到在所有图像都认为应该是暗的地方非常暗，但在图像不一致的地方变得模糊。</p>
<p>让我们对 7 做同样的事情，但一次将所有步骤放在一起以节省时间：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mean7 = stacked_sevens.mean(<span class="number">0</span>)</span><br><span class="line">show_image(mean7);</span><br></pre></td></tr></table></figure>
<p><img src="/image/dlcf_04in05.png" alt=""></p>
<p>现在让我们选择一个任意的 3，并测量它与我们的“理想数字”的<em>距离</em>。</p>
<h1 id="停下来思考一下！"><a href="#停下来思考一下！" class="headerlink" title="停下来思考一下！"></a>停下来思考一下！</h1><p>您如何计算特定图像与我们的每个理想数字之间的相似程度？在继续前进之前，请记得远离这本书，记录一些想法！研究表明，通过解决问题、实验和尝试新想法，您参与学习过程时，召回和理解会显著提高。</p>
<p>这是一个示例 3：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a_3 = stacked_threes[<span class="number">1</span>]</span><br><span class="line">show_image(a_3);</span><br></pre></td></tr></table></figure>
<p><img src="/image/dlcf_04in06.png" alt=""></p>
<p>我们如何确定它与我们理想的 3 之间的距离？我们不能简单地将此图像的像素之间的差异相加，并与理想数字进行比较。一些差异将是正的，而另一些将是负的，这些差异将相互抵消，导致一种情况，即在某些地方太暗而在其他地方太亮的图像可能被显示为与理想的总差异为零。那将是误导性的！</p>
<p>为了避免这种情况，数据科学家在这种情况下使用两种主要方法来测量距离：</p>
<ul>
<li><p>取差值的<em>绝对值</em>的平均值（绝对值是将负值替换为正值的函数）。这被称为<em>平均绝对差</em>或<em>L1 范数</em>。</p>
</li>
<li><p>取差值的<em>平方</em>的平均值（使所有值变为正数），然后取<em>平方根</em>（撤销平方）。这被称为<em>均方根误差</em>（RMSE）或<em>L2 范数</em>。</p>
</li>
</ul>
<h1 id="在pytorch中-取差值的绝对值的平均值（绝对值是将负值替换为正值的函数）。这被称为平均绝对差或L1-范数。"><a href="#在pytorch中-取差值的绝对值的平均值（绝对值是将负值替换为正值的函数）。这被称为平均绝对差或L1-范数。" class="headerlink" title="在pytorch中 取差值的绝对值的平均值（绝对值是将负值替换为正值的函数）。这被称为平均绝对差或L1 范数。"></a>在pytorch中 取差值的<em>绝对值</em>的平均值（绝对值是将负值替换为正值的函数）。这被称为<em>平均绝对差</em>或<em>L1 范数</em>。</h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dist_7_abs = (a_3 - mean7).<span class="built_in">abs</span>().mean()</span><br><span class="line">dist_7_sqr = ((a_3 - mean7)**<span class="number">2</span>).mean().sqrt()</span><br><span class="line">dist_7_abs,dist_7_sqr</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor(<span class="number">0.1586</span>), tensor(<span class="number">0.3021</span>))</span><br></pre></td></tr></table></figure>
<p>等同于：</p>
<p>PyTorch 已经提供了这两种作为<em>损失函数</em>。您会在<code>torch.nn.functional</code>中找到这些，PyTorch 团队建议将其导入为<code>F</code>（并且默认情况下以这个名称在 fastai 中可用）：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">F.l1_loss(a_3.<span class="built_in">float</span>(),mean7), F.mse_loss(a_3,mean7).sqrt()</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor(<span class="number">0.1586</span>), tensor(<span class="number">0.3021</span>))</span><br></pre></td></tr></table></figure>
<p>在这里，<code>MSE</code>代表<em>均方误差</em>，<code>l1</code>是标准数学术语<em>平均绝对值</em>的缩写（在数学中称为<em>L1 范数</em>）。</p>
<h1 id="L1-范数和-均方误差（MSE）之间的区别"><a href="#L1-范数和-均方误差（MSE）之间的区别" class="headerlink" title="L1 范数和 均方误差（MSE）之间的区别"></a>L1 范数和 均方误差（MSE）之间的区别</h1><p>直观地，L1 范数和均方误差（MSE）之间的区别在于，后者会比前者更严厉地惩罚更大的错误（并对小错误更宽容）。</p>
<h1 id="杰里米说"><a href="#杰里米说" class="headerlink" title="杰里米说"></a>杰里米说</h1><p>当我第一次遇到这个 L1 的东西时，我查了一下看它到底是什么意思。我在谷歌上发现它是使用“绝对值”作为“向量范数”，所以我查了“向量范数”并开始阅读：“给定一个实数或复数域 F 上的向量空间 V，V 上的范数是一个非负值的任意函数 p: V → [0,+∞)，具有以下属性：对于所有的 a ∈ F 和所有的 u, v ∈ V，p(u + v) ≤ p(u) + p(v)…”然后我停止阅读。“唉，我永远也理解不了数学！”我想，这已经是第一千次了。从那时起，我学到了每当实践中出现这些复杂的数学术语时，我可以用一点点代码来替换它们！比如，<em>L1 损失</em> 只等于 <code>(a-b).abs().mean()</code>，其中 <code>a</code> 和 <code>b</code> 是张量。我猜数学家们只是和我想法不同…我会确保在本书中，每当出现一些数学术语时，我会给你相应的代码片段，并用通俗的语言解释发生了什么。</p>
<p>我们刚刚在 PyTorch 张量上完成了各种数学运算。如果你之前在 PyTorch 中进行过数值编程，你可能会发现这些与 NumPy 数组相似。让我们来看看这两个重要的数据结构。</p>
<p>（请注意，fastai 在 NumPy 和 PyTorch 中添加了一些功能，使它们更加相似。如果本书中的任何代码在您的计算机上无法运行，可能是因为您忘记在笔记本的开头包含类似这样的一行代码：<code>from fastai.vision.all import *</code>。）</p>
<p>但是数组和张量是什么，为什么你应该关心呢？</p>
<p>Python 相对于许多语言来说速度较慢。在 Python、NumPy 或 PyTorch 中快速的任何东西，很可能是另一种语言（特别是 C）编写（并优化）的编译对象的包装器。事实上，<em>NumPy 数组和 PyTorch 张量可以比纯 Python 快几千倍完成计算</em>。</p>
<p>NumPy 数组是一个多维数据表，所有项都是相同类型的。由于可以是任何类型，它们甚至可以是数组的数组，内部数组可能是不同大小的 - 这被称为 <em>不规则数组</em>。通过“多维数据表”，我们指的是，例如，一个列表（一维）、一个表或矩阵（二维）、一个表的表或立方体（三维），等等。如果所有项都是简单类型，如整数或浮点数，NumPy 将它们存储为紧凑的 C 数据结构在内存中。这就是 NumPy 的优势所在。NumPy 有各种运算符和方法，可以在这些紧凑结构上以优化的 C 速度运行计算，因为它们是用优化的 C 编写的。</p>
<p>PyTorch 张量几乎与 NumPy 数组相同，但有一个额外的限制，可以解锁额外的功能。它与 NumPy 数组相同，也是一个多维数据表，所有项都是相同类型的。然而，限制是张量不能使用任何旧类型 - 它必须对所有组件使用单一基本数值类型。因此，张量不像真正的数组数组那样灵活。例如，PyTorch 张量不能是不规则的。它始终是一个形状规则的多维矩形结构。</p>
<p>NumPy 在这些结构上支持的绝大多数方法和运算符在 PyTorch 上也支持，但 PyTorch 张量具有额外的功能。一个主要功能是这些结构可以存在于 GPU 上，这样它们的计算将被优化为 GPU，并且可以运行得更快（给定大量值进行处理）。此外，PyTorch 可以自动计算这些操作的导数，包括操作的组合。正如你将看到的，没有这种能力，实际上是不可能进行深度学习的。</p>
<h1 id="如何有效地使用数组-张量-API-是最重要的新编码技能。"><a href="#如何有效地使用数组-张量-API-是最重要的新编码技能。" class="headerlink" title="如何有效地使用数组/张量 API 是最重要的新编码技能。"></a>如何有效地使用数组/张量 API 是最重要的新编码技能。</h1><p>要创建一个数组或张量，将列表（或列表的列表，或列表的列表的列表等）传递给<code>array</code>或<code>tensor</code>：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]]</span><br><span class="line">arr = array (data)</span><br><span class="line">tns = tensor(data)</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arr  <span class="comment"># numpy</span></span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tns  <span class="comment"># pytorch</span></span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br></pre></td></tr></table></figure>
<p>以下所有操作都是在张量上展示的，但 NumPy 数组的语法和结果是相同的。</p>
<p>你可以选择一行（请注意，与 Python 中的列表一样，张量是从 0 开始索引的，所以 1 指的是第二行/列）：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tns[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br></pre></td></tr></table></figure>
<p>或者通过使用<code>:</code>来指示<em>所有第一个轴</em>（我们有时将张量/数组的维度称为<em>轴</em>）选择一列。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tns[:,<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">2</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<p>你可以结合 Python 切片语法（<code>[*start*:*end*]</code>，其中<em><code>end</code></em>被排除）来选择一行或一列的一部分：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tns[<span class="number">1</span>,<span class="number">1</span>:<span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">5</span>, <span class="number">6</span>])</span><br></pre></td></tr></table></figure>
<p>你可以使用标准运算符，如<code>+</code>、<code>-</code>、<code>*</code>和<code>/</code>：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tns+<span class="number">1</span></span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]])</span><br></pre></td></tr></table></figure>
<p>张量有一个类型：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tns.<span class="built_in">type</span>()</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;torch.LongTensor&#x27;</span></span><br></pre></td></tr></table></figure>
<p>并且会根据需要自动更改该类型；例如，从<code>int</code>到<code>float</code>：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tns*<span class="number">1.5</span></span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1.5000</span>, <span class="number">3.0000</span>, <span class="number">4.5000</span>],</span><br><span class="line">        [<span class="number">6.0000</span>, <span class="number">7.5000</span>, <span class="number">9.0000</span>]])</span><br></pre></td></tr></table></figure>
<p>那么，我们的基准模型好吗？为了量化这一点，我们必须定义一个度量。</p>
<h1 id="使用广播计算度量"><a href="#使用广播计算度量" class="headerlink" title="使用广播计算度量"></a>使用广播计算度量</h1><p>回想一下<em>度量</em>是基于我们模型的预测和数据集中正确标签计算出来的一个数字，以告诉我们我们的模型有多好。例如，我们可以使用我们在上一节中看到的两个函数之一，均方误差或平均绝对误差，并计算整个数据集上它们的平均值。然而，这两个数字对大多数人来说并不是很容易理解；实际上，我们通常使用<em>准确度</em>作为分类模型的度量。</p>
<p>正如我们讨论过的，我们想要在<em>验证集</em>上计算我们的度量。这样我们就不会无意中过拟合——也就是说，训练一个模型只在我们的训练数据上表现良好。这对于我们在这里作为第一次尝试使用的像素相似度模型来说并不是真正的风险，因为它没有经过训练的组件，但我们仍然会使用一个验证集来遵循正常的实践，并为我们稍后的第二次尝试做好准备。</p>
<p>为了获得一个验证集，我们需要完全从训练数据中删除一些数据，这样模型根本就看不到它。事实证明，MNIST 数据集的创建者已经为我们做了这个。你还记得<em>valid</em>这个整个独立的目录吗？这个目录就是为此而设立的！</p>
<p>所以，让我们从那个目录中为我们的 3 和 7 创建张量。这些是我们将用来计算度量的张量，用来衡量我们第一次尝试模型的质量，这个度量衡量了与理想图像的距离：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">valid_3_tens = torch.stack([tensor(Image.<span class="built_in">open</span>(o))</span><br><span class="line">                            <span class="keyword">for</span> o <span class="keyword">in</span> (path/<span class="string">&#x27;valid&#x27;</span>/<span class="string">&#x27;3&#x27;</span>).ls()])</span><br><span class="line">valid_3_tens = valid_3_tens.<span class="built_in">float</span>()/<span class="number">255</span></span><br><span class="line">valid_7_tens = torch.stack([tensor(Image.<span class="built_in">open</span>(o))</span><br><span class="line">                            <span class="keyword">for</span> o <span class="keyword">in</span> (path/<span class="string">&#x27;valid&#x27;</span>/<span class="string">&#x27;7&#x27;</span>).ls()])</span><br><span class="line">valid_7_tens = valid_7_tens.<span class="built_in">float</span>()/<span class="number">255</span></span><br><span class="line">valid_3_tens.shape,valid_7_tens.shape</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(torch.Size([<span class="number">1010</span>, <span class="number">28</span>, <span class="number">28</span>]), torch.Size([<span class="number">1028</span>, <span class="number">28</span>, <span class="number">28</span>]))</span><br></pre></td></tr></table></figure>
<p>在进行操作时检查形状是一个好习惯。在这里我们看到两个张量，一个代表了 1,010 张大小为 28×28 的 3 的验证集，另一个代表了 1,028 张大小为 28×28 的 7 的验证集。</p>
<p>我们最终想要编写一个函数<code>is_3</code>，它将决定任意图像是 3 还是 7。它将通过确定任意图像更接近我们的两个“理想数字”中的哪一个来实现这一点。为此，我们需要定义<em>距离</em>的概念——即，计算两个图像之间距离的函数。</p>
<p>我们可以编写一个简单的函数，使用与我们在上一节中编写的表达式非常相似的表达式来计算平均绝对误差：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">mnist_distance</span>(<span class="params">a,b</span>): <span class="keyword">return</span> (a-b).<span class="built_in">abs</span>().mean((-<span class="number">1</span>,-<span class="number">2</span>))</span><br><span class="line">mnist_distance(a_3, mean3)</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="number">0.1114</span>)</span><br></pre></td></tr></table></figure>
<p>这是我们先前为这两个图像之间的距离计算的相同值，理想数字 3 <code>mean_3</code>和任意样本 3 <code>a_3</code>，它们都是形状为<code>[28,28]</code>的单个图像张量。</p>
<p>但是要计算整体准确度的指标，我们需要计算验证集中<em>每张</em>图像到理想数字 3 的距离。我们如何进行这种计算？我们可以编写一个循环，遍历验证集张量<code>valid_3_tens</code>中堆叠的所有单图像张量，其形状为<code>[1010,28,28]</code>，表示 1,010 张图像。但是有一种更好的方法。</p>
<p>当我们使用相同的距离函数，设计用于比较两个单个图像，但将表示 3 的验证集张量<code>valid_3_tens</code>作为参数传入时，会发生一些有趣的事情：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">valid_3_dist = mnist_distance(valid_3_tens, mean3)</span><br><span class="line">valid_3_dist, valid_3_dist.shape</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(tensor([<span class="number">0.1050</span>, <span class="number">0.1526</span>, <span class="number">0.1186</span>,  ..., <span class="number">0.1122</span>, <span class="number">0.1170</span>, <span class="number">0.1086</span>]),</span><br><span class="line"> torch.Size([<span class="number">1010</span>]))</span><br></pre></td></tr></table></figure>
<p>它没有抱怨形状不匹配，而是为每个单个图像返回了一个距离（即，长度为 1,010 的秩-1 张量）。这是如何发生的？</p>
<p>再看看我们的函数<code>mnist_distance</code>，您会看到我们在那里有减法<code>(a-b)</code>。魔术技巧在于 PyTorch 在尝试在不同秩的两个张量之间执行简单的减法操作时，将使用<em>广播</em>：它将自动扩展秩较小的张量，使其大小与秩较大的张量相同。广播是一种重要的功能，使张量代码更容易编写。</p>
<p>在广播后，使两个参数张量具有相同的秩后，PyTorch 对于秩相同的两个张量应用其通常的逻辑：它对两个张量的每个对应元素执行操作，并返回张量结果。例如：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]) + tensor([<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure>
<p>因此，在这种情况下，PyTorch 将<code>mean3</code>视为一个表示单个图像的秩-2 张量，就好像它是 1,010 个相同图像的副本，然后从我们的验证集中的每个 3 中减去每个副本。您期望这个张量的形状是什么？在查看这里的答案之前，请尝试自己想出来：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(valid_3_tens-mean3).shape</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([<span class="number">1010</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br></pre></td></tr></table></figure>
<p>我们正在计算我们的理想数字 3 与验证集中的每个 1,010 个 3 之间的差异，对于每个 28×28 图像，结果形状为<code>[1010,28,28]</code>。</p>
<p>有关广播实现的一些重要要点，使其不仅对于表达性有价值，而且对于性能也有价值：</p>
<ul>
<li><p>PyTorch 实际上并没有将<code>mean3</code>复制 1,010 次。它<em>假装</em>它是一个具有该形状的张量，但不分配任何额外内存。</p>
</li>
<li><p>它在 C 中完成整个计算（或者，如果您使用 GPU，则在 CUDA 中，相当于 GPU 上的 C），比纯 Python 快数万倍（在 GPU 上甚至快数百万倍！）。</p>
</li>
</ul>
<p>这适用于 PyTorch 中所有广播和逐元素操作和函数。<em>这是您要了解的最重要的技术，以创建高效的 PyTorch 代码。</em></p>
<p>接下来在<code>mnist_distance</code>中我们看到<code>abs</code>。现在您可能能猜到将其应用于张量时会发生什么。它将方法应用于张量中的每个单独元素，并返回结果的张量（即，它逐元素应用方法）。因此，在这种情况下，我们将得到 1,010 个绝对值。</p>
<p>最后，我们的函数调用<code>mean((-1,-2))</code>。元组<code>(-1,-2)</code>表示一系列轴。在 Python 中，<code>-1</code>指的是最后一个元素，<code>-2</code>指的是倒数第二个元素。因此，在这种情况下，这告诉 PyTorch 我们要对张量的最后两个轴的值进行平均。最后两个轴是图像的水平和垂直维度。在对最后两个轴进行平均后，我们只剩下第一个张量轴，它索引我们的图像，这就是为什么我们的最终大小是<code>(1010)</code>。换句话说，对于每个图像，我们对该图像中所有像素的强度进行了平均。</p>
<p>在本书中，我们将学习更多关于广播的知识，特别是在第十七章中，并且也会经常进行实践。</p>
<p>我们可以使用<code>mnist_distance</code>来确定一幅图像是否为 3，方法是使用以下逻辑：如果问题中的数字与理想的 3 之间的距离小于到理想的 7 的距离，则它是一个 3。这个函数将自动进行广播，并逐个应用，就像所有 PyTorch 函数和运算符一样：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">is_3</span>(<span class="params">x</span>): <span class="keyword">return</span> mnist_distance(x,mean3) &lt; mnist_distance(x,mean7)</span><br></pre></td></tr></table></figure>
<p>让我们在我们的示例案例上测试一下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">is_3(a_3), is_3(a_3).<span class="built_in">float</span>()</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor(<span class="literal">True</span>), tensor(<span class="number">1.</span>))</span><br></pre></td></tr></table></figure>
<p>请注意，当我们将布尔响应转换为浮点数时，<code>True</code>会得到<code>1.0</code>，<code>False</code>会得到<code>0.0</code>。</p>
<p>由于广播，我们还可以在所有 3 的完整验证集上进行测试：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">is_3(valid_3_tens)</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>,  ..., <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>])</span><br></pre></td></tr></table></figure>
<p>现在我们可以计算每个 3 和 7 的准确率，方法是对所有 3 的函数取平均值，对所有 7 的函数取其倒数的平均值：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">accuracy_3s =      is_3(valid_3_tens).<span class="built_in">float</span>() .mean()</span><br><span class="line">accuracy_7s = (<span class="number">1</span> - is_3(valid_7_tens).<span class="built_in">float</span>()).mean()</span><br><span class="line"></span><br><span class="line">accuracy_3s,accuracy_7s,(accuracy_3s+accuracy_7s)/<span class="number">2</span></span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor(<span class="number">0.9168</span>), tensor(<span class="number">0.9854</span>), tensor(<span class="number">0.9511</span>))</span><br></pre></td></tr></table></figure>
<p>这看起来是一个相当不错的开始！我们在 3 和 7 上都获得了超过 90%的准确率，我们已经看到了如何使用广播方便地定义度量。但让我们诚实一点：3 和 7 是非常不同的数字。到目前为止，我们只对 10 个可能的数字中的 2 个进行分类。所以我们需要做得更好！</p>
<p>为了做得更好，也许现在是时候尝试一个真正学习的系统了，一个可以自动修改自身以提高性能的系统。换句话说，现在是时候谈论训练过程和 SGD 了。</p>
<h1 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h1><p>你还记得 Arthur Samuel 在第一章中描述机器学习的方式吗？</p>
<blockquote>
<p>假设我们安排一些自动手段来测试任何当前权重分配的有效性，以实际性能为基础，并提供一种机制来改变权重分配以最大化性能。我们不需要详细了解这种程序的细节，就可以看到它可以完全自动化，并且可以看到一个这样编程的机器会从中学习。</p>
</blockquote>
<p>正如我们讨论过的，这是让我们拥有一个可以变得越来越好的模型的关键，可以学习。但我们的像素相似性方法实际上并没有做到这一点。我们没有任何权重分配，也没有任何根据测试权重分配的有效性来改进的方法。换句话说，我们无法通过修改一组参数来改进我们的像素相似性方法。为了充分利用深度学习的力量，我们首先必须按照 Samuel 描述的方式来表示我们的任务。</p>
<p>与其尝试找到图像与“理想图像”之间的相似性，我们可以查看每个单独的像素，并为每个像素提出一组权重，使得最高的权重与最有可能为特定类别的黑色像素相关联。例如，向右下方的像素不太可能被激活为 7，因此它们对于 7 的权重应该很低，但它们很可能被激活为 8，因此它们对于 8 的权重应该很高。这可以表示为一个函数和每个可能类别的一组权重值，例如，成为数字 8 的概率：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pr_eight</span>(<span class="params">x,w</span>) = (x*w).<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<p>在这里，我们假设<code>X</code>是图像，表示为一个向量—换句话说，所有行都堆叠在一起形成一个长长的单行。我们假设权重是一个向量<code>W</code>。如果我们有了这个函数，我们只需要一种方法来更新权重，使它们变得更好一点。通过这种方法，我们可以重复这个步骤多次，使权重变得越来越好，直到我们能够使它们尽可能好。</p>
<p>我们希望找到导致我们的函数对于那些是 8 的图像结果高，对于那些不是的图像结果低的向量<code>W</code>的特定值。搜索最佳向量<code>W</code>是搜索最佳函数以识别 8 的一种方式。（因为我们还没有使用深度神经网络，我们受到我们的函数能力的限制，我们将在本章后面解决这个约束。）</p>
<p>更具体地说，<font color=yellow>以下是将这个函数转化为机器学习分类器所需的步骤：</font></p>
<ol>
<li><p><em>初始化</em>权重。</p>
</li>
<li><p>对于每个图像，使用这些权重来<em>预测</em>它是 3 还是 7。</p>
</li>
<li><p>基于这些预测，计算模型有多好（它的<em>损失</em>）。</p>
</li>
<li><p>计算<em>梯度</em>，它衡量了每个权重的变化如何改变损失。</p>
</li>
<li><p>根据这个计算，<em>改变</em>（即，改变）所有权重。</p>
</li>
<li><p>回到步骤 2 并<em>重复</em>这个过程。</p>
</li>
<li><p>迭代直到你决定<em>停止</em>训练过程（例如，因为模型已经足够好或者你不想再等待了）。</p>
</li>
</ol>
<p>这七个步骤，如图 4-1 所示，是所有深度学习模型训练的关键。深度学习完全依赖于这些步骤，这是非常令人惊讶和反直觉的。令人惊奇的是，这个过程可以解决如此复杂的问题。但是，正如你将看到的，它确实可以！</p>
<p><img src="/image/dlcf_0401.png" alt="显示梯度下降步骤的图表"></p>
<h6 id="图-4-1-梯度下降过程"><a href="#图-4-1-梯度下降过程" class="headerlink" title="图 4-1. 梯度下降过程"></a>图 4-1. 梯度下降过程</h6><p>每个步骤都有许多方法，我们将在本书的其余部分学习它们。这些细节对于深度学习从业者来说非常重要，但事实证明，对于每个步骤的一般方法都遵循一些基本原则。以下是一些建议：</p>
<p>初始化</p>
<p>我们将参数初始化为随机值。这可能听起来令人惊讶。我们当然可以做其他选择，比如将它们初始化为该类别激活该像素的百分比—但由于我们已经知道我们有一种方法来改进这些权重，结果证明只是从随机权重开始就可以完全正常运行。</p>
<p>损失</p>
<p>这就是 Samuel 所说的<em>根据实际表现测试任何当前权重分配的有效性</em>。我们需要一个函数，如果模型的表现好，它将返回一个小的数字（标准方法是将小的损失视为好的，大的损失视为坏的，尽管这只是一种约定）。</p>
<p>步骤</p>
<p>一个简单的方法来判断一个权重是否应该增加一点或减少一点就是尝试一下：增加一点权重，看看损失是增加还是减少。一旦找到正确的方向，你可以再多改变一点或少改变一点，直到找到一个效果好的量。然而，这很慢！正如我们将看到的，微积分的魔力使我们能够直接找出每个权重应该朝哪个方向改变，大概改变多少，而不必尝试所有这些小的改变。这样做的方法是通过计算<em>梯度</em>。这只是一种性能优化；我们也可以通过使用更慢的手动过程得到完全相同的结果。</p>
<p>停止</p>
<p>一旦我们决定要为模型训练多少个周期（之前的列表中给出了一些建议），我们就会应用这个决定。对于我们的数字分类器，我们会继续训练，直到模型的准确率开始变差，或者我们用完时间为止。</p>
<p>在将这些步骤应用于我们的图像分类问题之前，让我们在一个更简单的情况下看看它们是什么样子。首先我们将定义一个非常简单的函数，二次函数—假设这是我们的损失函数，<code>x</code>是函数的权重参数：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x</span>): <span class="keyword">return</span> x**<span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>这是该函数的图表：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_function(f, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;x**2&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/image/dlcf_04in07.png" alt=""></p>
<p>我们之前描述的步骤序列从选择参数的随机值开始，并计算损失的值：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_function(f, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;x**2&#x27;</span>)</span><br><span class="line">plt.scatter(-<span class="number">1.5</span>, f(-<span class="number">1.5</span>), color=<span class="string">&#x27;red&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/image/dlcf_04in08.png" alt=""></p>
<p>现在我们来看看如果我们稍微增加或减少参数会发生什么—<em>调整</em>。这只是特定点的斜率：</p>
<p><img src="/image/dlcf_04in09.png" alt="显示在某一点的斜率的平方函数的图表"></p>
<p>我们可以稍微改变我们的权重朝着斜坡的方向，计算我们的损失和调整，然后再重复几次。最终，我们将到达曲线上的最低点：</p>
<p><img src="/image/dlcf_04in10.png" alt="梯度下降的示意图"></p>
<p>这个基本思想最早可以追溯到艾萨克·牛顿，他指出我们可以以这种方式优化任意函数。无论我们的函数变得多么复杂，梯度下降的这种基本方法不会有太大变化。我们在本书后面看到的唯一微小变化是一些方便的方法，可以让我们更快地找到更好的步骤。</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/04/28/fastaichapter3/" rel="prev" title="Fastai Chapter 3">
      <i class="fa fa-chevron-left"></i> Fastai Chapter 3
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%BA%95%E5%B1%82%EF%BC%9A%E8%AE%AD%E7%BB%83%E6%95%B0%E5%AD%97%E5%88%86%E7%B1%BB%E5%99%A8"><span class="nav-number">1.</span> <span class="nav-text">第四章：底层：训练数字分类器</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%83%8F%E7%B4%A0%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9A%84%E5%9F%BA%E7%A1%80"><span class="nav-number">2.</span> <span class="nav-text">像素：计算机视觉的基础</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%81%9C%E4%B8%8B%E6%9D%A5%E6%80%9D%E8%80%83%EF%BC%81"><span class="nav-number">3.</span> <span class="nav-text">停下来思考！</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95%EF%BC%9A%E5%83%8F%E7%B4%A0%E7%9B%B8%E4%BC%BC%E5%BA%A6"><span class="nav-number">4.</span> <span class="nav-text">第一次尝试：像素相似度</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%9C%AF%E8%AF%AD%EF%BC%9A%E5%9F%BA%E7%BA%BF"><span class="nav-number">5.</span> <span class="nav-text">术语：基线</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%97%E8%A1%A8%E6%8E%A8%E5%AF%BC"><span class="nav-number">6.</span> <span class="nav-text">列表推导</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%B3%E4%BA%8E%E7%BB%B4%E5%BA%A6"><span class="nav-number">7.</span> <span class="nav-text">关于维度</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%81%9C%E4%B8%8B%E6%9D%A5%E6%80%9D%E8%80%83%E4%B8%80%E4%B8%8B%EF%BC%81"><span class="nav-number">8.</span> <span class="nav-text">停下来思考一下！</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9C%A8pytorch%E4%B8%AD-%E5%8F%96%E5%B7%AE%E5%80%BC%E7%9A%84%E7%BB%9D%E5%AF%B9%E5%80%BC%E7%9A%84%E5%B9%B3%E5%9D%87%E5%80%BC%EF%BC%88%E7%BB%9D%E5%AF%B9%E5%80%BC%E6%98%AF%E5%B0%86%E8%B4%9F%E5%80%BC%E6%9B%BF%E6%8D%A2%E4%B8%BA%E6%AD%A3%E5%80%BC%E7%9A%84%E5%87%BD%E6%95%B0%EF%BC%89%E3%80%82%E8%BF%99%E8%A2%AB%E7%A7%B0%E4%B8%BA%E5%B9%B3%E5%9D%87%E7%BB%9D%E5%AF%B9%E5%B7%AE%E6%88%96L1-%E8%8C%83%E6%95%B0%E3%80%82"><span class="nav-number">9.</span> <span class="nav-text">在pytorch中 取差值的绝对值的平均值（绝对值是将负值替换为正值的函数）。这被称为平均绝对差或L1 范数。</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#L1-%E8%8C%83%E6%95%B0%E5%92%8C-%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE%EF%BC%88MSE%EF%BC%89%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">10.</span> <span class="nav-text">L1 范数和 均方误差（MSE）之间的区别</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%9D%B0%E9%87%8C%E7%B1%B3%E8%AF%B4"><span class="nav-number">11.</span> <span class="nav-text">杰里米说</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E6%9C%89%E6%95%88%E5%9C%B0%E4%BD%BF%E7%94%A8%E6%95%B0%E7%BB%84-%E5%BC%A0%E9%87%8F-API-%E6%98%AF%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E6%96%B0%E7%BC%96%E7%A0%81%E6%8A%80%E8%83%BD%E3%80%82"><span class="nav-number">12.</span> <span class="nav-text">如何有效地使用数组&#x2F;张量 API 是最重要的新编码技能。</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E5%B9%BF%E6%92%AD%E8%AE%A1%E7%AE%97%E5%BA%A6%E9%87%8F"><span class="nav-number">13.</span> <span class="nav-text">使用广播计算度量</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">14.</span> <span class="nav-text">随机梯度下降</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%9B%BE-4-1-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E8%BF%87%E7%A8%8B"><span class="nav-number">14.0.0.0.0.1.</span> <span class="nav-text">图 4-1. 梯度下降过程</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Wang Song"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Wang Song</p>
  <div class="site-description" itemprop="description">a graduate student working at Huzhou institute of Zhejiang University</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">8</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/SongSop" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;SongSop" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:3042903197@qq.com" title="E-Mail → mailto:3042903197@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Wang Song</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : 'forest',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  

</body>
</html>
