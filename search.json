[{"title":"Aliyun","url":"/2025/04/27/aliyun/","content":"前言因为在本次课程中本来要使用的的微软的azure服务因为在国外而且服务部署很不稳定无法使用所以打算将文中使用的bing rearch v7换成阿里云的图像搜素服务进行fastai chapter 2的代码演示。所以本次博客记录的是对阿里云图像搜索SDK(阿里云的图像搜索服务在python上并不支持api的使用方式给出的是sdk的使用办法虽然说对于个人用户而言更加的安全高效但是需要对课程中的代码进行大修改)的学习及使用核对课程代码的修改运行。\n阿里云python sdk接口列表\n\n\n\n接口名称\n接口说明\n\n\n\n\nAdd\n增加图片。\n\n\nSearchImageByPro\n使用图片进行搜索。\n\n\nSearchImageByName\n指定名称，使用已入库的图片进行搜索。\n\n\nSearchImageByTotal\n使用文本进行搜索。（仅在服务类型为商品名和收藏类时可以使用。）\n\n\nDelete\n删除图片。\n\n\nUpdateImage\n修改图片。\n\n\nDictal\n查询你的消息。\n\n\nDumpMeta\n无信息导出任务。\n\n\nDumpMetaList\n无信息导出任务列表。\n\n\nBatchTask\n批量任务。\n\n\nBatchTaskList\n批量任务列表。\n\n\nCompareSimilarByImage\n比较所有图片的相似度。\n\n\n\n\n准备工作\n在安装和使用阿里云SDK前，确保您已经注册阿里云账号并生成访问密钥（AccessKey）。详情请参见创建AccessKey。\n\n使用如下方式安装依赖包。\n\n\npip install alibabacloud_imagesearch20201214\nAdd 接口\nexample：from alibabacloud_imagesearch20201214.client import Clientfrom alibabacloud_imagesearch20201214.models import AddImageAdvanceRequestfrom alibabacloud_tea_openapi.models import Configfrom alibabacloud_tea_util.models import RuntimeOptionsdef addImage():    request = AddImageAdvanceRequest()    # 必填，图像搜索实例名称。注意是实例名称不是实例ID。购买后通过上云层管控台实例信息一栏查看：https://imagesearch.console.aliyun.com/overview    request.instance_name = &#x27;&lt;instanceName&gt;&#x27;    # 必填，商品id，最多支持 256个字符。    # 一个商品可有多张图片。    request.product_id = &#x27;&lt;productId&gt;&#x27;    # 必填，图片名称，最多支持 256个字符。    # 1. ProductId + PicName唯一确定一张图片。    # 2. 如果多次添加图片具有相同的ProductId + PicName，以最后一次添加为准，前面添加的图片将被覆盖。    request.pic_name = &#x27;&lt;picName&gt;&#x27;    # 图片内容，最多支持 4MB大小图片以及5s的传输等待时间。当前仅支持PNG、JPG、JPEG、BMP、GIF、WEBP、TIFF、PPM格式图片；    # 对于商品、商标、通用图片搜索，图片长和宽的像素必须都大于等于100且小于等于4096；    # 对于布料搜索，图片长和宽的像素必须都大于等于448且小于等于4096；    # 图像中不能带有旋转信息；    # 使用URL方式释放下方注释即可。       # url = &#x27;&lt;fileUrl&gt;&#x27;        # f = BytesIO(requests.get(url).content)      # 使用图片file新增    f = open(&#x27;&lt;filePath&gt;&#x27;, &#x27;rb&#x27;)    request.pic_content_object = f    # 选填，商品类目。    # 1. 对于商品搜索：若设置类目，则以设置的为准；若不设置类目，将由系统进行类目预测，预测的类目结果可在Response中获取 。    # 2. 对于布料、商标、通用搜索：不论是否设置类目，系统会将类目设置为88888888。    request.category_id = 3    # 选填，用户自定义的内容，最多支持4096个字符。    # 查询时会返回该字段。例如可添加图片的描述等文本。    request.custom_content = &quot;this is a simple test&quot;    # 选填，整数类型属性，可用于查询时过滤，查询时会返回该字段。    #  例如不同的站点的图片/不同用户的图片，可以设置不同的IntAttr，查询时通过过滤来达到隔离的目的    request.int_attr = 56    # 选填，字符串类型属性，最多支持 128个字符。可用于查询时过滤，查询时会返回该字段。    request.str_attr = &quot;test&quot;    # 选填，是否需要进行主体识别，默认为true。    # 1.为true时，由系统进行主体识别，以识别的主体进行搜索，主体识别结果可在Response中获取。    # 2.为false时，则不进行主体识别，以整张图进行搜索。    # 3.对于布料图片搜索，此参数会被忽略，系统会以整张图进行搜索。    request.crop = True    # 选填，图片的主体区域，格式为 x1,x2,y1,y2, 其中 x1,y1 是左上角的点，x2，y2是右下角的点。设置的region 区域不要超过图片的边界。    # 若用户设置了Region，则不论Crop参数为何值，都将以用户输入Region进行搜索。    # 对于布料图片搜索，此参数会被忽略，系统会以整张图进行搜索。    request.region = &quot;167,467,221,407&quot;    config = Config()    # 创建AK/SK参考：https://help.aliyun.com/document_detail/116401.htm    # 阿里云账号AccessKey拥有所有API的访问权限，建议您使用RAM用户进行API访问或日常运维。    # 强烈建议不要把AccessKey ID和AccessKey Secret保存到工程代码里，否则可能导致AccessKey泄露，威胁您账号下所有资源的安全。    # 本示例以将AccessKey ID和AccessKey Secret保存在环境变量为例说明。您也可以根据业务需要，保存到配置文件里。    config.access_key_id = os.environ[&#x27;CC_AK_ENV&#x27;]    config.access_key_secret = os.environ[&#x27;CC_SK_ENV&#x27;]    # 请更换成您购买实例的区域，例如购买的是杭州区域，则endpoint=&#x27;imagesearch.cn-hangzhou.aliyuncs.com&#x27;    config.endpoint = &#x27;imagesearch.[regionId].aliyuncs.com&#x27;    # 以下为内网（VPC）访问方式    # 说明：内网（VPC）访问：仅限同区域ECS或资源的访问，例如您购买的图像搜索实例是华东2（上海），那么您的ECS或资源也必须在华东2（上海）才能通过内网VPC地址访问图搜服务，否则会调用不通，如果遇到调用不通，请先检查您的ECS或资源与图像搜索是否在同一个区域。    # config.endpointType = &#x27;internal&#x27;  // 如果是内网访问图像搜索服务，则endpointType为必填项，值统一为&#x27;internal&#x27;    # config.endpoint = &#x27;imagesearch-vpc.[regionId].aliyuncs.com&#x27; // 为内网访问（VPC）地址，请您更换为您购买实例的区域，例如您购买实例的区域为杭州，则endpoint=&#x27;imagesearch-vpc.cn-hangzhou.aliyuncs.com&#x27;    # 请您更换成您购买实例的区域，例如您购买的实例区域为杭州，则更换为regionId=&#x27;cn-hangzhou&#x27;       config.region_id = &#x27;&lt;regionId&gt;&#x27;    config.type = &#x27;access_key&#x27;    client = Client(config)    runtime_option = RuntimeOptions()    response = client.add_image_advance(request, runtime_option)    print(response.to_map())    f.close()if __name__ == &#x27;__main__&#x27;:    addImage()\nresult:\n&#123;  &#x27;RequestId&#x27;: &#x27;7F769FFC-4F45-476E-BE6C-E4EF82E012A7&#x27;,  &#x27;Success&#x27;: True,  &#x27;Message&#x27;: &#x27;success&#x27;,  &#x27;Code&#x27;: 0,  &#x27;PicInfo&#x27;: &#123;    &#x27;CategoryId&#x27;: 20,    &#x27;Region&#x27;: &#x27;474,747,497,784&#x27;  &#125;&#125;\nSearchImagebyName 接口\nexample：\nfrom alibabacloud_imagesearch20201214.client import Clientfrom alibabacloud_imagesearch20201214.models import SearchImageByNameRequestfrom alibabacloud_tea_openapi.models import Configfrom alibabacloud_tea_util.models import RuntimeOptionsdef searchImageByName() :    request = SearchImageByNameRequest()    # 必填，图像搜索实例名称。注意是实例名称不是实例ID。购买后通过上云层管控台实例信息一栏查看：https://imagesearch.console.aliyun.com/overview    request.instance_name = &#x27;&lt;instanceName&gt;&#x27;    # 必填，商品id，最多支持 256个字符。    # 一个商品可有多张图片。    request.product_id = &#x27;&lt;productId&gt;&#x27;    # 必填，图片名称，最多支持 256个字符。    # 1. ProductId + PicName唯一确定一张图片。    # 2. 如果多次添加图片具有相同的ProductId + PicName，以最后一次添加为准，前面添加的图片将被覆盖。    request.pic_name = &#x27;&lt;picName&gt;&#x27;    # 选填，商品类目。    # 1. 对于商品搜索：若设置类目，则以设置的为准；若不设置类目，将由系统进行类目预测，预测的类目结果可在Response中获取 。    # 2. 对于布料、商标、通用搜索：不论是否设置类目，系统会将类目设置为88888888。    request.category_id = 3    # 选填，返回结果的数目。取值范围：1-100。默认值：10。    request.num = 10    # 选填，返回结果的起始位置。取值范围：0-499。默认值：0。    request.start = 0    # 选填，是否需要进行主体识别，默认为true。    # 1.为true时，由系统进行主体识别，以识别的主体进行搜索，主体识别结果可在Response中获取。    # 2.为false时，则不进行主体识别，以整张图进行搜索。    # 3.对于布料图片搜索，此参数会被忽略，系统会以整张图进行搜索。    request.crop = True    # 选填，图片的主体区域，格式为 x1,x2,y1,y2, 其中 x1,y1 是左上角的点，x2，y2是右下角的点。设置的region 区域不要超过图片的边界。    # 若用户设置了Region，则不论Crop参数为何值，都将以用户输入Region进行搜索。    # 3.对于布料图片搜索，此参数会被忽略，系统会以整张图进行搜索。    request.region=&quot;167,467,221,407&quot;    # 选填，过滤条件    # int_attr支持的操作符有&gt;、&gt;=、&lt;、&lt;=、=，str_attr支持的操作符有=和!=，多个条件之支持AND和OR进行连接。    # 示例：    #  1. 根据IntAttr过滤结果，int_attr&gt;=100    #  2. 根据StrAttr过滤结果，str_attr!=&quot;value1&quot;    #  3. 根据IntAttr和StrAttr联合过滤结果，int_attr=1000 AND str_attr=&quot;value1&quot;    request.filter=&quot;int_attr=56 AND str_attr=\\&quot;test\\&quot;&quot;    config = Config()    # 创建AK/SK参考：https://help.aliyun.com/document_detail/116401.htm    # 阿里云账号AccessKey拥有所有API的访问权限，建议您使用RAM用户进行API访问或日常运维。    # 强烈建议不要把AccessKey ID和AccessKey Secret保存到工程代码里，否则可能导致AccessKey泄露，威胁您账号下所有资源的安全。    # 本示例以将AccessKey ID和AccessKey Secret保存在环境变量为例说明。您也可以根据业务需要，保存到配置文件里。    config.access_key_id = os.environ[&#x27;CC_AK_ENV&#x27;]    config.access_key_secret = os.environ[&#x27;CC_SK_ENV&#x27;]    # 请更换成您购买实例的区域，例如购买的是杭州区域，则endpoint=&#x27;imagesearch.cn-hangzhou.aliyuncs.com&#x27;    config.endpoint = &#x27;imagesearch.&lt;regionId&gt;.aliyuncs.com&#x27;    # 以下为内网（VPC）访问方式    # 说明：内网（VPC）访问：仅限同区域ECS或资源的访问，例如您购买的图像搜索实例是华东2（上海），那么您的ECS或资源也必须在华东2（上海）才能通过内网VPC地址访问图搜服务，否则会调用不通，如果遇到调用不通，请先检查您的ECS或资源与图像搜索是否在同一个区域。    # config.endpointType = &#x27;internal&#x27;  // 如果是内网访问图像搜索服务，则endpointType为必填项，值统一为&#x27;internal&#x27;    # config.endpoint = &#x27;imagesearch-vpc.&lt;regionId&gt;.aliyuncs.com&#x27; // 为内网访问（VPC）地址，请您更换为您购买实例的区域，例如您购买实例的区域为杭州，则endpoint=&#x27;imagesearch-vpc.cn-hangzhou.aliyuncs.com&#x27;    # 请您更换成您购买实例的区域，例如您购买的实例区域为杭州，则更换为regionId=&#x27;cn-hangzhou&#x27;    config.region_id = &#x27;&lt;regionId&gt;&#x27;    config.type = &#x27;access_key&#x27;    client = Client(config)    response = client.search_image_by_name(request)    print(response.to_map())if __name__ == &#x27;__main__&#x27;:    searchImageByName()\nresult:\n\n&#123;  &#x27;RequestId&#x27;: &#x27;7BC00158-3B9B-49C4-9E25-FFEC28AF3CE8&#x27;,  &#x27;Success&#x27;: True,  &#x27;Code&#x27;: 0,  &#x27;Msg&#x27;: &#x27;success&#x27;,  &#x27;Auctions&#x27;: [&#123;    &#x27;CategoryId&#x27;: 20,    &#x27;ProductId&#x27;: &#x27;test-version-001&#x27;,    &#x27;PicName&#x27;: &#x27;test-version-001.jpg&#x27;,    &#x27;CustomContent&#x27;: None,    &#x27;score&#x27;:1.0,    &#x27;SortExprValues&#x27;: &#x27;5.37633353624177e+24;0&#x27;,    &#x27;IntAttr&#x27;: None,    &#x27;StrAttr&#x27;: None  &#125;, &#123;    &#x27;CategoryId&#x27;: 20,    &#x27;ProductId&#x27;: &#x27;test_0426_1&#x27;,    &#x27;PicName&#x27;: &#x27;test_0426_1.png&#x27;,    &#x27;CustomContent&#x27;: None,    &#x27;score&#x27;:1.0,    &#x27;SortExprValues&#x27;: &#x27;2.71303606033325;263&#x27;,    &#x27;IntAttr&#x27;: None,    &#x27;StrAttr&#x27;: None  &#125;],  &#x27;Head&#x27;: &#123;    &#x27;DocsReturn&#x27;: 5,    &#x27;DocsFound&#x27;: 5,    &#x27;SearchTime&#x27;: 15  &#125;,  &#x27;PicInfo&#x27;: &#123;    &#x27;CategoryId&#x27;: 20,    &#x27;Region&#x27;: None,    &#x27;AllCategories&#x27;: [&#123;      &#x27;Id&#x27;: 0,      &#x27;Name&#x27;: &#x27;Tops&#x27;    &#125;, &#123;      &#x27;Id&#x27;: 1,      &#x27;Name&#x27;: &#x27;Dress&#x27;    &#125;, &#123;      &#x27;Id&#x27;: 2,      &#x27;Name&#x27;: &#x27;Bottoms&#x27;    &#125;, &#123;      &#x27;Id&#x27;: 3,      &#x27;Name&#x27;: &#x27;Bag&#x27;    &#125;, &#123;      &#x27;Id&#x27;: 4,      &#x27;Name&#x27;: &#x27;Shoes&#x27;    &#125;, &#123;      &#x27;Id&#x27;: 5,      &#x27;Name&#x27;: &#x27;Accessories&#x27;    &#125;, &#123;      &#x27;Id&#x27;: 6,      &#x27;Name&#x27;: &#x27;Snack&#x27;    &#125;, &#123;      &#x27;Id&#x27;: 7,      &#x27;Name&#x27;: &#x27;Makeup&#x27;    &#125;, &#123;      &#x27;Id&#x27;: 8,      &#x27;Name&#x27;: &#x27;Bottle&#x27;    &#125;, &#123;      &#x27;Id&#x27;: 9,      &#x27;Name&#x27;: &#x27;Furniture&#x27;    &#125;, &#123;      &#x27;Id&#x27;: 20,      &#x27;Name&#x27;: &#x27;Toy&#x27;    &#125;, &#123;      &#x27;Id&#x27;: 21,      &#x27;Name&#x27;: &#x27;Underwear&#x27;    &#125;, &#123;      &#x27;Id&#x27;: 22,      &#x27;Name&#x27;: &#x27;Digital device&#x27;    &#125;, &#123;      &#x27;Id&#x27;: 88888888,      &#x27;Name&#x27;: &#x27;Other&#x27;    &#125;],    &#x27;MultiRegion&#x27;: [&#123;        &#x27;Region&#x27;: &#x27;112,440,76,387&#x27;     &#125;]  &#125;&#125;"},{"title":"Medicalrobot","url":"/2025/04/22/Medicalrobot/","content":"","tags":["ros  project  Maintain the code"]},{"title":"如何在github上写自己的blog(主要作为学习工作记录)","url":"/2025/04/22/blogtmp/","content":"前言为什么要写这个博客，因为在fastai课程中看到其中的一个观点：\n开始写作吧！我们的学生发现最有帮助巩固对这一材料的理解的事情之一是把它写下来。尝试教给别人是对你对一个主题的理解的最好测试。即使你从不向任何人展示你的写作，这也是有帮助的，但如果你分享了，那就更好了！因此，我们建议，如果你还没有开始写博客，那么现在就开始吧。现在你已经完成了这一章并学会了如何训练和部署模型，你已经可以写下你的第一篇关于深度学习之旅的博客文章了。你有什么惊讶？你在你的领域看到了深度学习的机会？你看到了什么障碍？\nfast.ai 的联合创始人 Rachel Thomas 在文章“为什么你（是的，你）应该写博客”中写道：\n\n我会给年轻的自己的最重要建议是尽早开始写博客。以下是一些写博客的理由：\n\n这就像一份简历，只不过更好。我知道有几个人因为写博客文章而得到了工作机会！\n\n帮助你学习。组织知识总是帮助我整合自己的想法。是否理解某事的一个测试是你是否能够向别人解释它。博客文章是一个很好的方式。\n\n我通过我的博客文章收到了参加会议的邀请和演讲邀请。我因为写了一篇关于我不喜欢 TensorFlow 的博客文章而被邀请参加 TensorFlow Dev Summit（太棒了！）。\n\n结识新朋友。我认识了几个回复我写的博客文章的人。\n\n节省时间。每当你通过电子邮件多次回答同一个问题时，你应该把它变成一篇博客文章，这样下次有人问起时你就更容易分享了。\n\n\n也许她最重要的建议是：\n\n你最适合帮助比你落后一步的人。这些材料仍然新鲜在你的脑海中。许多专家已经忘记了作为初学者（或中级学习者）时的感受，忘记了当你第一次听到这个话题时为什么难以理解。你特定背景、风格和知识水平的背景将为你所写的内容带来不同的视角。\n\n我们已经提供了如何在附录 A 中设置博客的详细信息。如果你还没有博客，现在就看看吧，因为我们有一个非常好的方法让你免费开始写博客，没有广告，甚至可以使用 Jupyter Notebook！\n上传blog方法在md文件中写好了文档之后保存并放置在C:\\Users\\song\\Desktop\\blog\\diary\\source_posts文件夹中然后依次输入下列指令上传\n$ hexo clean\n$ hexo generate\n$ hexo deploy\n即可将文档上传到github\n本地查看方法$ hexo serve\n神奇的我让ai帮我写了一个bat现在可以一键部署了您别说别的还挺好用，倍地道，嘀嘀嘀地道到…………..\ncall hexo cleanif %errorlevel% neq 0 (    echo error：%errorlevel%    goto error)echo.echo generate...call hexo generateif %errorlevel% neq 0 (    echo error：%errorlevel%    goto error)echo.echo deploy...call hexo deployif %errorlevel% neq 0 (    echo error：%errorlevel%    goto error)echo.echo [Success] all Success!!pauseexit /b 0:errorecho.echo ******************************echo * fatal error! pls check log *echo ******************************pauseexit /b 1\n有一说一其实应该再搞一个.sh的给linux用，但是无所谓了等要用的时候再让ai写吧。\n"},{"title":"关于Colab的使用","url":"/2025/04/24/colab/","content":"关于ColabGoogle Colab是谷歌提供的免费Jupyter 笔记本环境，不需要什么设置与环境配置就可以使用，完全在云端运行。不影响本地的使用。\nGoogle Colab为研究者提供一定免费的GPU，可以编写和执行代码，所有这些都可通过浏览器免费使用。同学们可以在上面轻松地跑 Tensorflow、Pytorch 等深度学习框架。\n尽管Google Colab提供了一定的免费资源，但资源量是受限制的，所有 Colab 运行时都会在一段时间后重置。Colab Pro 订阅者的使用量仍会受到限制，但相比非订阅者可享有的限额要多出大约一倍。Colab Pro+ 订阅者还可获享更高的稳定性。\n关于Google Drivergoogle云端硬盘，也称为谷歌云端硬盘，是互联网巨头谷歌公司推出的一项在线云存储服务，英文全称是Google Drive。目前有免费和付费两种模式，免费用户可以获取15G的空间，付费用户根据套餐可以选择最大20TB的储存空间\n利用colab进行fastai课程中的代码运行因为本来为教学课程为了快速上手并没有充分的时间进行环境的配置，同时我的gpu也并非一个较好的水位（rtx2060），加上之前在复现论文时用过colab的免费服务，被google的慷慨和大方震惊，故在进行deeping learning的课程学习时也准备使用colab进行代码的操作。\nstep 1:在github fastbook项目主页下选择对应的学习章节选择对应的学习章节进行打开即可转移到相应的项目colab。\n\n需要注意这个课程选择的主页仅当主页语言为英文时才会出现。\nstep2 :在进入colab页面后选择托管硬件为gpu点击 代码执行程序 —&gt; 更改运行时类型 —&gt;选择 T4 GPU(当然土豪是随意 充钱即可享受更强大的gpu)\n最后进行连接，点击需要测试的代码块，即可线上进行代码的测试\n\ncolab测试运行结果在运行安装环境配置的代码块时出现了报错\n\n在forums.fast.ai论坛上进行查找发现该问题并不影响后续程序的执行\n\n执行第一个进行cnn网络训练得到猫狗识别的模型的程序结果\n\n总结完成了深度学习的重要的一步在线上对代码进行运行，在目前算力设备都极其昂贵的背景下，选择线上的代码服务进行模型的训练显得尤其具有性价比，掌握该项技能能够使得我的科研和工作突破某些因为算力不足的限制，同时对于学习更加的方便。\n"},{"title":"Fastai Chapter 3","url":"/2025/04/28/fastaichapter3/","content":"前言正如我们在第一章和第二章中讨论的，有时机器学习模型可能出错。它们可能有错误。它们可能被呈现出以前没有见过的数据，并以我们意料之外的方式行事。或者它们可能完全按设计工作，但被用于我们非常希望它们永远不要被用于的事情。\n因为深度学习是如此强大的工具，可以用于很多事情，所以我们特别需要考虑我们选择的后果。哲学上对伦理的研究是对对错的研究，包括我们如何定义这些术语，识别对错行为，以及理解行为和后果之间的联系。数据伦理领域已经存在很长时间，许多学者都专注于这个领域。它被用来帮助定义许多司法管辖区的政策；它被用在大大小小的公司中，考虑如何最好地确保产品开发对社会的良好结果；它被研究人员用来确保他们正在做的工作被用于好的目的，而不是坏的目的。\n因此，作为一个深度学习从业者，你很可能在某个时候会面临需要考虑数据伦理的情况。那么数据伦理是什么？它是伦理学的一个子领域，所以让我们从那里开始。\n 第三章貌似是深度学习的思政课开始就是数据伦理感觉可以摸鱼了。\n\n结论鉴于我已经在学校修过《工程伦理了》所以让我们跳过这一章\n"},{"title":"Fastai Chapter 2","url":"/2025/04/24/fastaichapter2/","content":"前言本章主要探讨的是深度学习的实践，我们需要知道深度学习的能力和限制，以至于让我们我至于低估或是对深度学习的能力和限制有过高的期盼。\n从模型到生成在本章中，我们将使用一个计算机视觉示例来查看创建深度学习应用的端到端过程。更具体地说，我们将构建一个熊分类器！在这个过程中，我们将讨论深度学习的能力和限制，探讨如何创建数据集，在实践中使用深度学习时可能遇到的问题等等。许多关键点同样适用于其他深度学习问题，例如第一章中的问题。如果您解决的问题在关键方面类似于我们的示例问题，我们期望您可以快速获得极好的结果，而只需很少的代码。\n开始深度学习的项目首先开始深度学习像是在制作一份独属于你自己的三明治！（尽管他可能没有那么好吃！但是你必须会自己做它！）只有通过处理自己的项目，您才能获得构建和使用模型的真实经验。\n就像做三明治一样，你不可能找到一块完美的火腿或者是生菜进行制作。（一个切的薄厚不均的火腿片或是不太完整的生菜可能并不会影响三明治的味道所以告别完美主义不要让你的工作停滞不前）\n无论您是为了自己的学习还是为了在组织中的实际应用而进行项目，您都希望能够快速开始。我们看到许多学生、研究人员和行业从业者在试图找到他们完美的数据集时浪费了几个月甚至几年的时间。目标不是找到“完美”的数据集或项目，而只是开始并从那里迭代。如果您采取这种方法，您将在完美主义者仍处于规划阶段时进行第三次迭代学习和改进！\n我们还建议您在项目中端到端迭代；不要花几个月来微调您的模型，或打磨完美的 GUI，或标记完美的数据集……相反，尽可能在合理的时间内完成每一步，一直到最后。例如，如果您的最终目标是一个在手机上运行的应用程序，那么每次迭代后您都应该拥有这个。但也许在早期迭代中您会采取捷径；例如，在远程服务器上进行所有处理，并使用简单的响应式 Web 应用程序。通过完成项目的端到端，您将看到最棘手的部分在哪里，以及哪些部分对最终结果产生最大影响。\nSylvain’s tips刚开始的时候应该选择一个熟悉的你能接触到大量数据的领域，如果没有也应该选择一个已经被应用于深度学习的领域。不然你就会和无头苍蝇一样不知道自己错在哪里。\n深度学习应用的领域分析（书的日期为2020年但现在是2025年我会结合自己的一些项目经历进行分析）计算机视觉书中说到：深度学习尚未用于分析图像的许多领域，但在已经尝试过的领域中，几乎普遍表明计算机可以至少与人类一样好地识别图像中的物品，甚至是经过专门训练的人，如放射科医生。这被称为物体识别。深度学习还擅长识别图像中物体的位置，并可以突出它们的位置并命名每个找到的物体。这被称为物体检测（在我们在第一章中看到的变体中，每个像素根据其所属的对象类型进行分类—这被称为分割）。\n深度学习算法通常不擅长识别结构或风格与用于训练模型的图像明显不同的图像。例如，如果训练数据中没有黑白图像，模型可能在黑白图像上表现不佳。同样，如果训练数据不包含手绘图像，模型可能在手绘图像上表现不佳。没有一般方法可以检查训练集中缺少哪些类型的图像，但我们将在本章中展示一些方法，以尝试识别当模型在生产中使用时数据中出现意外图像类型的情况（这被称为检查域外数据）。\n物体检测系统面临的一个主要挑战是图像标记可能会很慢且昂贵。目前有很多工作正在进行中，旨在开发工具以尝试使这种标记更快速、更容易，并且需要更少的手工标签来训练准确的物体检测模型。一个特别有帮助的方法是合成生成输入图像的变化，例如通过旋转它们或改变它们的亮度和对比度；这被称为数据增强，并且对文本和其他类型的模型也很有效。我们将在本章中详细讨论这一点。\n另一个要考虑的问题是，尽管您的问题可能看起来不像是一个计算机视觉问题，但通过一点想象力可能可以将其转变为一个。例如，如果您要分类的是声音，您可以尝试将声音转换为其声学波形的图像，然后在这些图像上训练模型。\n但是实际上现在深度学习在计算机视觉的领域目前在繁荣发展就我而言所使用过的yolo视觉模型简直的惊为天人的存在\n自然语言处理计算机擅长基于类别对短文档和长文档进行分类，例如垃圾邮件或非垃圾邮件、情感（例如，评论是积极的还是消极的）、作者、来源网站等。我们不知道在这个领域是否有任何严格的工作来比较计算机和人类，但从经验上看，我们认为深度学习的性能在这些任务上与人类的性能相似。\n深度学习还擅长生成与上下文相关的文本，例如回复社交媒体帖子，并模仿特定作者的风格。它还擅长使这些内容对人类具有吸引力—事实上，甚至比人类生成的文本更具吸引力。然而，深度学习不擅长生成正确的回应！例如，我们没有可靠的方法来将医学信息知识库与深度学习模型结合起来，以生成医学上正确的自然语言回应。这是危险的，因为很容易创建对外行人看来具有吸引力但实际上完全不正确的内容。\n另一个问题是，社交媒体上的上下文适当、高度引人入胜的回应可能被大规模使用——比以前见过的任何喷子农场规模大几千倍——来传播虚假信息，制造动荡，鼓励冲突。一般来说，文本生成模型总是在技术上略领先于识别自动生成文本的模型。例如，可以使用一个能够识别人工生成内容的模型来实际改进创建该内容的生成器，直到分类模型无法完成其任务为止。\n尽管存在这些问题，深度学习在自然语言处理中有许多应用：可以用来将文本从一种语言翻译成另一种语言，将长篇文档总结为更快消化的内容，找到感兴趣概念的所有提及等。不幸的是，翻译或总结可能包含完全错误的信息！然而，性能已经足够好，许多人正在使用这些系统——例如，谷歌的在线翻译系统（以及我们所知道的每个其他在线服务）都是基于深度学习的。\n原来早在深度学习提出之除就发现其在大语言模型上的潜力更加强大，要是早读这本书我就早买大语言模型企业的股票飞黄腾达了，果然还是要多看书QAQ\n结合文本和图像深度学习将文本和图像结合成一个单一模型的能力通常比大多数人直觉期望的要好得多。例如，一个深度学习模型可以在输入图像上进行训练，输出用英语编写的标题，并且可以学会为新图像自动生成令人惊讶地适当的标题！但是，我们再次提出与前一节讨论的相同警告：不能保证这些标题是正确的。\n由于这个严重问题，我们通常建议深度学习不要作为完全自动化的过程，而是作为模型和人类用户密切互动的过程的一部分。这可能使人类的生产力比完全手动方法高出几个数量级，并且比仅使用人类更准确。\n例如，自动系统可以直接从 CT 扫描中识别潜在的中风患者，并发送高优先级警报，以便快速查看这些扫描。治疗中风只有三个小时的时间窗口，因此这种快速的反馈循环可以挽救生命。同时，所有扫描仍然可以按照通常的方式发送给放射科医生，因此不会减少人类的参与。其他深度学习模型可以自动测量扫描中看到的物品，并将这些测量结果插入报告中，警告放射科医生可能错过的发现，并告诉他们可能相关的其他病例。\n这是我作为研究生阶段最关心的点，讲真的把这个用在机器人身上非常的酷\n表格数据对于分析时间序列和表格数据，深度学习最近取得了巨大进展。然而，深度学习通常作为多种模型集成的一部分使用。如果您已经有一个正在使用随机森林或梯度提升机（流行的表格建模工具，您很快将了解）的系统，那么切换到或添加深度学习可能不会带来任何显著的改进。\n深度学习确实大大增加了您可以包含的列的种类——例如，包含自然语言（书名、评论等）和高基数分类列（即包含大量离散选择的内容，如邮政编码或产品 ID）。不过，与随机森林或梯度提升机相比，深度学习模型通常需要更长的训练时间，尽管由于提供 GPU 加速的库（如RAPIDS），情况正在改变。我们在第九章中详细介绍了所有这些方法的优缺点。\n或许等我走头无路开路边摊的时候可以设计一个来控制我的成本\n推荐系统推荐系统实际上只是一种特殊类型的表格数据。特别是，它们通常具有代表用户的高基数分类变量，以及代表产品（或类似物品）的另一个变量。像亚马逊这样的公司将客户所做的每一次购买都表示为一个巨大的稀疏矩阵，其中客户是行，产品是列。一旦他们以这种格式拥有数据，数据科学家们会应用某种形式的协同过滤来填充矩阵。例如，如果客户 A 购买产品 1 和 10，客户 B 购买产品 1、2、4 和 10，引擎将推荐 A 购买 2 和 4。\n由于深度学习模型擅长处理高基数分类变量，它们非常擅长处理推荐系统。尤其是当将这些变量与其他类型的数据（如自然语言或图像）结合时，它们就像处理表格数据一样发挥作用。它们还可以很好地将所有这些类型的信息与其他元数据（如用户信息、先前交易等）表示为表格进行组合。\n然而，几乎所有的机器学习方法都有一个缺点，那就是它们只告诉你一个特定用户可能喜欢哪些产品，而不是对用户有用的推荐。用户可能喜欢的产品的许多种推荐可能根本不会有任何帮助——例如，如果用户已经熟悉这些产品，或者如果它们只是用户已经购买过的产品的不同包装（例如，当他们已经拥有该套装中的每一件物品时，推荐一个小说的套装）。Jeremy 喜欢读特里·普拉切特的书，有一段时间亚马逊一直在向他推荐特里·普拉切特的书，这实际上并不是有用的，因为他已经知道这些书了！\n愚蠢的b站视频推荐算法就是这样的。我都已经考上了研究生他还一直给我推考研的视频\n其他数据类型通常，您会发现特定领域的数据类型非常适合现有的类别。例如，蛋白质链看起来很像自然语言文档，因为它们是由复杂关系和意义贯穿整个序列的离散令牌组成的长序列。事实上，使用 NLP 深度学习方法是许多类型蛋白质分析的最先进方法。另一个例子，声音可以表示为频谱图，可以被视为图像；标准的图像深度学习方法在频谱图上表现得非常好。\n讲真的这个非常的神奇感觉生物和控制结合在一起大有所为！！！快去买生物科技公司的股票！！！！\n驱动系统方法许多准确的模型对任何人都没有用，而许多不准确的模型却非常有用。为了确保您的建模工作在实践中有用，您需要考虑您的工作将如何使用。2012 年，Jeremy 与 Margit Zwemer 和 Mike Loukides 一起提出了一种称为驱动系统方法的思考这个问题的方法。\n驱动系统方法，如图 2-2 所示，详细介绍在“设计出色的数据产品”中。基本思想是从考虑您的目标开始，然后考虑您可以采取哪些行动来实现该目标以及您拥有的（或可以获取的）可以帮助的数据，然后构建一个模型，您可以使用该模型确定为实现目标而采取的最佳行动。\n\n图 2-2. 驱动系统方法考虑自动驾驶汽车中的模型：您希望帮助汽车安全地从 A 点驾驶到 B 点，而无需人为干预。出色的预测建模是解决方案的重要组成部分，但它并不是独立存在的；随着产品变得更加复杂，它会消失在管道中。使用自动驾驶汽车的人完全不知道使其运行的数百（甚至数千）个模型和海量数据。但随着数据科学家构建越来越复杂的产品，他们需要一种系统化的设计方法。\n我们使用数据不仅仅是为了生成更多数据（以预测的形式），而是为了产生可操作的结果。这是 Drivetrain 方法的目标。首先要明确定义一个明确的目标。例如，当谷歌创建其第一个搜索引擎时，考虑了“用户在输入搜索查询时的主要目标是什么？”这导致了谷歌的目标，即“显示最相关的搜索结果”。下一步是考虑您可以拉动的杠杆（即您可以采取的行动）以更好地实现该目标。在谷歌的情况下，这是搜索结果的排名。第三步是考虑他们需要什么新数据来生成这样的排名；他们意识到关于哪些页面链接到哪些其他页面的隐含信息可以用于此目的。\n只有在完成了这前三个步骤之后，我们才开始考虑构建预测模型。我们的目标和可用的杠杆，我们已经拥有的数据以及我们需要收集的额外数据，决定了我们可以构建的模型。这些模型将以杠杆和任何不可控变量作为输入；模型的输出可以结合起来预测我们的目标的最终状态。\n让我们考虑另一个例子：推荐系统。推荐引擎的目标是通过推荐客户不会在没有推荐的情况下购买的物品来推动额外的销售。杠杆是推荐的排名。必须收集新数据以生成将导致新销售的推荐。这将需要进行许多随机实验，以收集关于各种客户的各种推荐的数据。这是很少有组织采取的一步；但是没有它，您就没有所需的信息来根据您的真正目标（更多销售！）优化推荐。\n最后，您可以为购买概率构建两个模型，条件是看到或没有看到推荐。这两个概率之间的差异是给定推荐给客户的效用函数。在算法推荐客户已经拒绝的熟悉书籍（两个组成部分都很小）或者他们本来就会购买的书籍（两个组成部分都很大并互相抵消）的情况下，效用函数会很低。\n正如您所看到的，在实践中，您的模型的实际实施通常需要比仅仅训练一个模型更多！您通常需要运行实验来收集更多数据，并考虑如何将您的模型整合到您正在开发的整个系统中。说到数据，现在让我们专注于如何为您的项目找到数据。\n保持自己能够获取互联网图像这里需要高校验证来获取免费的Azure的bing图像搜索api的服务（今天才发现我没有高校邮箱现在申请不知道几天可以申请下来）。所以下面需要用到api的代码我就不运行了。欠着等申请下了在运行key = &#x27;XXX&#x27;\n或者，如果您在命令行上感到自在，您可以在终端中设置它\nexport AZURE_SEARCH_KEY=*your_key_here*\n然后重新启动 Jupyter 服务器，在一个单元格中键入以下内容，并执行：\nkey = os.environ[&#x27;AZURE_SEARCH_KEY&#x27;]\n设置了key之后，您可以使用search_images_bing。这个函数是在线笔记本中包含的小utils类提供的（如果您不确定一个函数是在哪里定义的，您可以在笔记本中输入它来找出，如下所示）：\nsearch_images_bing\n&lt;function utils.search_images_bing(key, term, min_sz=128)&gt;\n让我们尝试一下这个函数：\nresults = search_images_bing(key, &#x27;grizzly bear&#x27;)ims = results.attrgot(&#x27;content_url&#x27;)len(ims)\n150\n我们已成功下载了 150 只灰熊的 URL（或者至少是 Bing 图像搜索为该搜索词找到的图像）。让我们看一个：\ndest = &#x27;images/grizzly.jpg&#x27;download_url(ims[0], dest)\nim = Image.open(dest)im.to_thumb(128,128)\n\n这似乎运行得很好，所以让我们使用 fastai 的download_images来下载每个搜索词的所有 URL。我们将每个放在一个单独的文件夹中：\nbear_types = &#x27;grizzly&#x27;,&#x27;black&#x27;,&#x27;teddy&#x27;path = Path(&#x27;bears&#x27;)\nif not path.exists():    path.mkdir()    for o in bear_types:        dest = (path/o)        dest.mkdir(exist_ok=True)        results = search_images_bing(key, f&#x27;&#123;o&#125; bear&#x27;)        download_images(dest, urls=results.attrgot(&#x27;content_url&#x27;))\n我们的文件夹中有图像文件，正如我们所期望的那样：\nfns = get_image_files(path)fns\n(#421) [Path(&#x27;bears/black/00000095.jpg&#x27;),Path(&#x27;bears/black/00000133.jpg&#x27;),Path(&#x27; &gt; bears/black/00000062.jpg&#x27;),Path(&#x27;bears/black/00000023.jpg&#x27;),Path(&#x27;bears/black &gt; /00000029.jpg&#x27;),Path(&#x27;bears/black/00000094.jpg&#x27;),Path(&#x27;bears/black/00000124.j &gt; pg&#x27;),Path(&#x27;bears/black/00000056.jpeg&#x27;),Path(&#x27;bears/black/00000046.jpg&#x27;),Path( &gt; &#x27;bears/black/00000045.jpg&#x27;)...]\nJeremy 说我就是喜欢在 Jupyter 笔记本中工作的这一点！逐步构建我想要的东西并在每一步检查我的工作是如此容易。我犯了很多错误，所以这对我真的很有帮助。\n通常当我们从互联网下载文件时，会有一些文件损坏。让我们检查一下：\nfailed = verify_images(fns)failed\n(#0) []\n要删除所有失败的图像，您可以使用unlink。像大多数返回集合的 fastai 函数一样，verify_images返回一个类型为L的对象，其中包括map方法。这会在集合的每个元素上调用传递的函数：\nfailed.map(Path.unlink);\n在这个过程中要注意的一件事是：正如我们在第一章中讨论的，模型只能反映用于训练它们的数据。而世界充满了有偏见的数据，这最终会反映在，例如，Bing 图像搜索（我们用来创建数据集的）。例如，假设您有兴趣创建一个应用程序，可以帮助用户确定他们是否拥有健康的皮肤，因此您训练了一个模型，该模型基于搜索结果（比如）“健康皮肤”。图 2-3 展示了您将获得的结果类型。\n\n图 2-3. 用于健康皮肤检测器的数据？使用此作为训练数据，您最终不会得到一个健康皮肤检测器，而是一个年轻白人女性触摸她的脸检测器！一定要仔细考虑您可能在应用程序中实际看到的数据类型，并仔细检查以确保所有这些类型都反映在您模型的源数据中。（感谢 Deb Raji 提出了健康皮肤的例子。请查看她的论文“可操作的审计：调查公开命名商业 AI 产品偏见性能结果的影响”以获取更多有关模型偏见的迷人见解。）\n现在我们已经下载了一些数据，我们需要将其组装成适合模型训练的格式。在 fastai 中，这意味着创建一个名为DataLoaders的对象。\n术语：DataLoaders一个 fastai 类，存储您传递给它的多个DataLoader对象——通常是一个train和一个valid，尽管可以有任意数量。前两个作为属性提供。\n在本书的后面，您还将了解Dataset和Datasets类，它们具有相同的关系。要将我们下载的数据转换为DataLoaders对象，我们至少需要告诉 fastai 四件事：\n\n我们正在处理什么类型的数据\n\n如何获取项目列表\n\n如何为这些项目打标签\n\n如何创建验证集\n\n\n到目前为止，我们已经看到了一些特定组合的工厂方法，当您有一个应用程序和数据结构恰好适合这些预定义方法时，这些方法非常方便。当您不适用时，fastai 有一个名为数据块 API的极其灵活的系统。使用此 API，您可以完全自定义创建DataLoaders的每个阶段。这是我们需要为刚刚下载的数据集创建DataLoaders的步骤：\nbears = DataBlock(    blocks=(ImageBlock, CategoryBlock),    get_items=get_image_files,    splitter=RandomSplitter(valid_pct=0.2, seed=42),    get_y=parent_label,    item_tfms=Resize(128))\n让我们依次查看每个参数。首先，我们提供一个元组，指定我们希望独立变量和因变量的类型：\nblocks=(ImageBlock, CategoryBlock)\n独立变量是我们用来进行预测的东西，因变量是我们的目标。在这种情况下，我们的独立变量是一组图像，我们的因变量是每个图像的类别（熊的类型）。在本书的其余部分中，我们将看到许多其他类型的块。\n对于这个DataLoaders，我们的基础项目将是文件路径。我们必须告诉 fastai 如何获取这些文件的列表。get_image_files函数接受一个路径，并返回该路径中所有图像的列表（默认情况下递归）：\nget_items=get_image_files\n通常，您下载的数据集已经定义了验证集。有时，这是通过将用于训练和验证集的图像放入不同的文件夹中来完成的。有时，这是通过提供一个 CSV 文件，在该文件中，每个文件名都与应该在其中的数据集一起列出。有许多可以完成此操作的方法，fastai 提供了一种通用方法，允许您使用其预定义类之一或编写自己的类。\n在这种情况下，我们希望随机拆分我们的训练和验证集。但是，我们希望每次运行此笔记本时都具有相同的训练/验证拆分，因此我们固定随机种子（计算机实际上不知道如何创建随机数，而只是创建看起来随机的数字列表；如果您每次都为该列表提供相同的起始点——称为种子，那么您将每次都获得完全相同的列表）。\nsplitter=RandomSplitter(valid_pct=0.2, seed=42)\n自变量通常被称为x，因变量通常被称为y。在这里，我们告诉 fastai 要调用哪个函数来创建数据集中的标签：\nget_y=parent_label\nparent_label是 fastai 提供的一个函数，它简单地获取文件所在文件夹的名称。因为我们将每个熊图像放入基于熊类型的文件夹中，这将为我们提供所需的标签。\n我们的图像大小各不相同，这对深度学习是一个问题：我们不是一次向模型提供一个图像，而是多个图像（我们称之为mini-batch）。为了将它们分组到一个大数组（通常称为张量）中，以便通过我们的模型，它们都需要是相同的大小。因此，我们需要添加一个转换，将这些图像调整为相同的大小。Item transforms是在每个单独项目上运行的代码片段，无论是图像、类别还是其他。fastai 包含许多预定义的转换；我们在这里使用Resize转换，并指定大小为 128 像素：\nitem_tfms=Resize(128)\n这个命令给了我们一个DataBlock对象。这就像创建DataLoaders的模板。我们仍然需要告诉 fastai 我们数据的实际来源——在这种情况下，图像所在的路径：\ndls = bears.dataloaders(path)\nDataLoaders包括验证和训练DataLoader。DataLoader是一个类，它一次向 GPU 提供几个项目的批次。我们将在下一章中更多地了解这个类。当您循环遍历DataLoader时，fastai 会一次给您 64 个（默认值）项目，全部堆叠到一个单一张量中。我们可以通过在DataLoader上调用show_batch方法来查看其中一些项目：\ndls.valid.show_batch(max_n=4, nrows=1)\n\n默认情况下，Resize会将图像裁剪成适合请求大小的正方形形状，使用完整的宽度或高度。这可能会导致丢失一些重要细节。或者，您可以要求 fastai 用零（黑色）填充图像，或者压缩/拉伸它们：\nbears = bears.new(item_tfms=Resize(128, ResizeMethod.Squish))dls = bears.dataloaders(path)dls.valid.show_batch(max_n=4, nrows=1)\n\nbears = bears.new(item_tfms=Resize(128, ResizeMethod.Pad, pad_mode=&#x27;zeros&#x27;))dls = bears.dataloaders(path)dls.valid.show_batch(max_n=4, nrows=1)\n\n所有这些方法似乎都有些浪费或问题。如果我们压缩或拉伸图像，它们最终会变成不现实的形状，导致模型学习到事物看起来与实际情况不同，这会导致更低的准确性。如果我们裁剪图像，我们会移除一些允许我们进行识别的特征。例如，如果我们试图识别狗或猫的品种，我们可能会裁剪掉区分相似品种所需的身体或面部的关键部分。如果我们填充图像，就会有很多空白空间，这对我们的模型来说只是浪费计算，并导致我们实际使用的图像部分具有较低的有效分辨率。\n相反，我们在实践中通常做的是随机选择图像的一部分，然后裁剪到该部分。在每个纪元（即数据集中所有图像的完整遍历），我们随机选择每个图像的不同部分。这意味着我们的模型可以学习关注和识别图像中的不同特征。这也反映了图像在现实世界中的工作方式：同一物体的不同照片可能以略有不同的方式构图。\n事实上，一个完全未经训练的神经网络对图像的行为一无所知。它甚至不认识当一个物体旋转一度时，它仍然是同一物体的图片！因此，通过训练神经网络使用物体在略有不同位置并且大小略有不同的图像的示例，有助于它理解物体的基本概念，以及如何在图像中表示它。\n这里是另一个示例，我们将Resize替换为RandomResizedCrop，这是提供刚才描述行为的转换。传递的最重要参数是min_scale，它确定每次选择图像的最小部分：\nbears = bears.new(item_tfms=RandomResizedCrop(128, min_scale=0.3))dls = bears.dataloaders(path)dls.train.show_batch(max_n=4, nrows=1, unique=True)\n\n在这里，我们使用了unique=True，以便将相同图像重复使用不同版本的RandomResizedCrop变换。\nRandomResizedCrop是更一般的数据增强技术的一个具体示例。\n数据增强数据增强指的是创建输入数据的随机变化，使它们看起来不同但不改变数据的含义。对于图像的常见数据增强技术包括旋转、翻转、透视变形、亮度变化和对比度变化。对于我们在这里使用的自然照片图像，我们发现一组标准的增强技术与aug_transforms函数一起提供，效果非常好。\n因为我们的图像现在都是相同大小，我们可以使用 GPU 将这些增强应用于整个批次的图像，这将节省大量时间。要告诉 fastai 我们要在批次上使用这些变换，我们使用batch_tfms参数（请注意，在此示例中我们没有使用RandomResizedCrop，这样您可以更清楚地看到差异；出于同样的原因，我们使用了默认值的两倍的增强量）：\nbears = bears.new(item_tfms=Resize(128), batch_tfms=aug_transforms(mult=2))dls = bears.dataloaders(path)dls.train.show_batch(max_n=8, nrows=2, unique=True)\n\n现在我们已经将数据组装成适合模型训练的格式，让我们使用它来训练一个图像分类器。\n训练您的模型，并使用它来清理您的数据现在是时候使用与第一章中相同的代码行来训练我们的熊分类器了。对于我们的问题，我们没有太多的数据（每种熊最多 150 张图片），因此为了训练我们的模型，我们将使用RandomResizedCrop，图像大小为 224 像素，这对于图像分类来说是相当标准的，并且使用默认的aug_transforms：\nbears = bears.new(    item_tfms=RandomResizedCrop(224, min_scale=0.5),    batch_tfms=aug_transforms())dls = bears.dataloaders(path)\n现在我们可以按照通常的方式创建我们的Learner并进行微调：\nlearn = cnn_learner(dls, resnet18, metrics=error_rate)learn.fine_tune(4)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.235733\n0.212541\n0.087302\n00:05\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n—-\n—-\n—-\n—-\n—-\n\n\n0\n0.213371\n0.112450\n0.023810\n00:05\n\n\n1\n0.173855\n0.072306\n0.023810\n00:06\n\n\n2\n0.147096\n0.039068\n0.015873\n00:06\n\n\n3\n0.123984\n0.026801\n0.015873\n00:06\n\n\n\n\n现在让我们看看模型犯的错误主要是认为灰熊是泰迪熊（这对安全性来说是不好的！），还是认为灰熊是黑熊，或者其他情况。为了可视化这一点，我们可以创建一个混淆矩阵：interp = ClassificationInterpretation.from_learner(learn)interp.plot_confusion_matrix()\n\n行代表数据集中所有黑色、灰熊和泰迪熊，列分别代表模型预测为黑色、灰熊和泰迪熊的图像。因此，矩阵的对角线显示了被正确分类的图像，而非对角线的单元格代表被错误分类的图像。这是 fastai 允许您查看模型结果的许多方式之一。当然，这是使用验证集计算的。通过颜色编码，目标是在对角线以外的地方都是白色，而在对角线上我们希望是深蓝色。我们的熊分类器几乎没有犯错！\n看到我们的错误发生在哪里是有帮助的，以便确定它们是由数据集问题（例如，根本不是熊的图像，或者标记错误）还是模型问题（也许它无法处理使用不同光照或从不同角度拍摄的图像等）。为了做到这一点，我们可以根据损失对图像进行排序。\n损失是一个数字，如果模型不正确（尤其是如果它对其不正确的答案也很自信），或者如果它是正确的但对其正确答案不自信，那么损失就会更高。在第二部分的开头，我们将深入学习损失是如何计算和在训练过程中使用的。现在，plot_top_losses向我们展示了数据集中损失最高的图像。正如输出的标题所说，每个图像都标有四个内容：预测、实际（目标标签）、损失和概率。这里的概率是模型对其预测分配的置信水平，从零到一：\ninterp.plot_top_losses(5, nrows=1)\n\n这个输出显示，损失最高的图像是一个被预测为“灰熊”的图像，且置信度很高。然而，根据我们的必应图像搜索，它被标记为“黑熊”。我们不是熊专家，但在我们看来，这个标签显然是错误的！我们可能应该将其标签更改为“灰熊”。\n进行数据清洗的直观方法是在训练模型之前进行。但正如您在本例中所看到的，模型可以帮助您更快速、更轻松地找到数据问题。因此，我们通常更喜欢先训练一个快速简单的模型，然后使用它来帮助我们进行数据清洗。\nfastai 包括一个方便的用于数据清洗的 GUI，名为ImageClassifierCleaner，它允许您选择一个类别和训练与验证集，并查看损失最高的图像（按顺序），以及菜单允许选择要删除或重新标记的图像：\ncleaner = ImageClassifierCleaner(learn)cleaner\n\n我们可以看到在我们的“黑熊”中有一张包含两只熊的图片：一只灰熊，一只黑熊。因此，我们应该在此图片下的菜单中选择&lt;Delete&gt;。ImageClassifierCleaner不会为您删除或更改标签；它只会返回要更改的项目的索引。因此，例如，要删除（取消链接）所有选定要删除的图像，我们将运行以下命令：\nfor idx in cleaner.delete(): cleaner.fns[idx].unlink()\n要移动我们选择了不同类别的图像，我们将运行以下命令：\nfor idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)\nSylvain’s tips清理数据并为您的模型做好准备是数据科学家面临的两个最大挑战；他们说这需要他们 90%的时间。fastai 库旨在提供尽可能简单的工具。\n在本书中，我们将看到更多基于模型驱动的数据清洗示例。一旦我们清理了数据，我们就可以重新训练我们的模型。自己尝试一下，看看你的准确性是否有所提高！\n不需要大数据通过这些步骤清理数据集后，我们通常在这个任务上看到 100%的准确性。即使我们下载的图像比我们在这里使用的每类 150 张要少得多，我们也能看到这个结果。正如您所看到的，您需要大量数据才能进行深度学习的常见抱怨可能与事实相去甚远！\n现在我们已经训练了我们的模型，让我们看看如何部署它以便在实践中使用。\n将您的模型转化为在线应用程序现在我们将看看将这个模型转化为一个可工作的在线应用程序需要什么。我们将只创建一个基本的工作原型；在本书中，我们没有范围来教授您有关 Web 应用程序开发的所有细节。\n使用模型进行推断一旦您拥有一个满意的模型，您需要保存它，以便随后将其复制到一个服务器上，在那里您将在生产中使用它。请记住，模型由两部分组成：架构和训练的参数。保存模型的最简单方法是保存这两部分，因为这样，当您加载模型时，您可以确保具有匹配的架构和参数。要保存这两部分，请使用export方法。\n这种方法甚至保存了如何创建您的DataLoaders的定义。这很重要，因为否则您将不得不重新定义如何转换您的数据以便在生产中使用您的模型。fastai 默认使用验证集DataLoader进行推理，因此不会应用数据增强，这通常是您想要的。\n当您调用export时，fastai 将保存一个名为export.pkl的文件：\nlearn.export()\n让我们通过使用 fastai 添加到 Python 的Path类的ls方法来检查文件是否存在：\npath = Path()path.ls(file_exts=&#x27;.pkl&#x27;)\n(#1) [Path(&#x27;export.pkl&#x27;)]\n您需要这个文件在您部署应用程序的任何地方。现在，让我们尝试在我们的笔记本中创建一个简单的应用程序。\n当我们使用模型进行预测而不是训练时，我们称之为推理。要从导出的文件创建我们的推理学习者，我们使用load_learner（在这种情况下，这并不是真正必要的，因为我们已经在笔记本中有一个工作的Learner；我们在这里这样做是为了让您看到整个过程的始终）：\nlearn_inf = load_learner(path/&#x27;export.pkl&#x27;)\n在进行推理时，通常一次只为一个图像获取预测。要做到这一点，将文件名传递给predict：\nlearn_inf.predict(&#x27;images/grizzly.jpg&#x27;)\n(&#x27;grizzly&#x27;, tensor(1), tensor([9.0767e-06, 9.9999e-01, 1.5748e-07]))\n这返回了三个东西：以与您最初提供的格式相同的预测类别（在本例中，这是一个字符串），预测类别的索引以及每个类别的概率。最后两个是基于DataLoaders的vocab中类别的顺序；也就是说，所有可能类别的存储列表。在推理时，您可以将DataLoaders作为Learner的属性访问：\nlearn_inf.dls.vocab\n(#3) [&#x27;black&#x27;,&#x27;grizzly&#x27;,&#x27;teddy&#x27;]\n我们可以看到，如果我们使用predict返回的整数索引到 vocab 中，我们会得到“灰熊”，这是预期的。另外，请注意，如果我们在概率列表中进行索引，我们会看到几乎有 1.00 的概率这是一只灰熊。\n我们知道如何从保存的模型中进行预测，因此我们拥有开始构建我们的应用程序所需的一切。我们可以直接在 Jupyter 笔记本中完成。\n从模型创建一个笔记本应用要在应用程序中使用我们的模型，我们可以简单地将predict方法视为常规函数。因此，使用任何应用程序开发人员可用的各种框架和技术都可以创建一个从模型创建的应用程序。\n然而，大多数数据科学家并不熟悉 Web 应用程序开发领域。因此，让我们尝试使用您目前已经了解的东西：事实证明，我们可以仅使用 Jupyter 笔记本创建一个完整的工作 Web 应用程序！使这一切成为可能的两个因素如下：\n\nIPython 小部件(ipywidgets)\n\nVoilà\n\n\nIPython 小部件是 GUI 组件，它在 Web 浏览器中将 JavaScript 和 Python 功能结合在一起，并可以在 Jupyter 笔记本中创建和使用。例如，我们在本章前面看到的图像清理器完全是用 IPython 小部件编写的。但是，我们不希望要求我们的应用程序用户自己运行 Jupyter。\n这就是Voilà存在的原因。它是一个使 IPython 小部件应用程序可供最终用户使用的系统，而无需他们使用 Jupyter。Voilà利用了一个事实，即笔记本已经是一种 Web 应用程序，只是另一个复杂的依赖于另一个 Web 应用程序：Jupyter 本身的 Web 应用程序。基本上，它帮助我们自动将我们已经隐式创建的复杂 Web 应用程序（笔记本）转换为一个更简单、更易部署的 Web 应用程序，它的功能类似于普通的 Web 应用程序，而不是笔记本。\n但是我们仍然可以在笔记本中开发的优势，因此使用 ipywidgets，我们可以逐步构建我们的 GUI。我们将使用这种方法创建一个简单的图像分类器。首先，我们需要一个文件上传小部件：\nbtn_upload = widgets.FileUpload()btn_upload\n\n现在我们可以获取图像：\nimg = PILImage.create(btn_upload.data[-1])\n\n我们可以使用Output小部件来显示它：\nout_pl = widgets.Output()out_pl.clear_output()with out_pl: display(img.to_thumb(128,128))out_pl\n\n然后我们可以得到我们的预测：\npred,pred_idx,probs = learn_inf.predict(img)\n并使用Label来显示它们：\nlbl_pred = widgets.Label()lbl_pred.value = f&#x27;Prediction: &#123;pred&#125;; Probability: &#123;probs[pred_idx]:.04f&#125;&#x27;lbl_pred\n预测：灰熊；概率：1.0000\n我们需要一个按钮来进行分类。它看起来与上传按钮完全相同：\nbtn_run = widgets.Button(description=&#x27;Classify&#x27;)btn_run\n我们还需要一个点击事件处理程序；也就是说，当按下按钮时将调用的函数。我们可以简单地复制之前的代码行：\ndef on_click_classify(change):    img = PILImage.create(btn_upload.data[-1])    out_pl.clear_output()    with out_pl: display(img.to_thumb(128,128))    pred,pred_idx,probs = learn_inf.predict(img)    lbl_pred.value = f&#x27;Prediction: &#123;pred&#125;; Probability: &#123;probs[pred_idx]:.04f&#125;&#x27;btn_run.on_click(on_click_classify)\n您现在可以通过单击按钮来测试按钮，您应该会看到图像和预测会自动更新！\n现在，我们可以将它们全部放在一个垂直框（VBox）中，以完成我们的 GUI：\nVBox([widgets.Label(&#x27;Select your bear!&#x27;),      btn_upload, btn_run, out_pl, lbl_pred])\n\n我们已经编写了所有必要的应用程序代码。下一步是将其转换为我们可以部署的内容。\n将您的笔记本变成一个真正的应用程序现在我们在这个 Jupyter 笔记本中已经让一切运转起来了，我们可以创建我们的应用程序。为此，请启动一个新的笔记本，并仅添加创建和显示所需小部件的代码，以及任何要显示的文本的 Markdown。查看书中存储库中的bear_classifier笔记本，看看我们创建的简单笔记本应用程序。\n接下来，如果您尚未安装 Voilà，请将这些行复制到笔记本单元格中并执行：\n!pip install voila!jupyter serverextension enable voila --sys-prefix\n以!开头的单元格不包含 Python 代码，而是包含传递给您的 shell（bash，Windows PowerShell 等）的代码。如果您习惯使用命令行，我们将在本书中更详细地讨论这一点，您当然可以直接在终端中键入这两行（不带!前缀）。在这种情况下，第一行安装voila库和应用程序，第二行将其连接到您现有的 Jupyter 笔记本。\nVoilà运行 Jupyter 笔记本，就像您现在使用的 Jupyter 笔记本服务器一样，但它还做了一件非常重要的事情：它删除了所有单元格输入，仅显示输出（包括 ipywidgets），以及您的 Markdown 单元格。因此，剩下的是一个 Web 应用程序！要将您的笔记本视为 Voilà Web 应用程序，请将浏览器 URL 中的“notebooks”一词替换为“voila/render”。您将看到与您的笔记本相同的内容，但没有任何代码单元格。\n当然，您不需要使用 Voilà或 ipywidgets。您的模型只是一个可以调用的函数（pred，pred_idx，probs = learn.predict（img）），因此您可以将其与任何框架一起使用，托管在任何平台上。您可以将在 ipywidgets 和 Voilà中原型设计的内容稍后转换为常规 Web 应用程序。我们在本书中展示这种方法，因为我们认为这是数据科学家和其他不是 Web 开发专家的人从其模型创建应用程序的绝佳方式。\n我们有了我们的应用程序；现在让我们部署它！\n部署您的应用程序正如您现在所知，几乎任何有用的深度学习模型都需要 GPU 来训练。那么，在生产中使用该模型需要 GPU 吗？不需要！您几乎可以肯定在生产中不需要 GPU 来提供您的模型。这样做有几个原因：\n\n正如我们所见，GPU 仅在并行执行大量相同工作时才有用。如果您正在进行（比如）图像分类，通常一次只会对一个用户的图像进行分类，而且通常在一张图像中没有足够的工作量可以让 GPU 忙碌足够长的时间以使其非常有效。因此，CPU 通常更具成本效益。\n\n另一种选择可能是等待一些用户提交他们的图像，然后将它们批量处理并一次性在 GPU 上处理。但是这样会让用户等待，而不是立即得到答案！而且您需要一个高流量的网站才能实现这一点。如果您确实需要这种功能，您可以使用诸如 Microsoft 的ONNX Runtime或AWS SageMaker之类的工具。\n\n处理 GPU 推理的复杂性很大。特别是，GPU 的内存需要仔细手动管理，您需要一个仔细的排队系统，以确保一次只处理一个批次。\n\nCPU 服务器的市场竞争要比 GPU 服务器更激烈，因此 CPU 服务器有更便宜的选项可供选择。\n\n\n由于 GPU 服务的复杂性，许多系统已经出现尝试自动化此过程。然而，管理和运行这些系统也很复杂，通常需要将您的模型编译成专门针对该系统的不同形式。通常最好避免处理这种复杂性，直到/除非您的应用程序变得足够受欢迎，以至于您有明显的财务理由这样做。\n至少对于您的应用程序的初始原型以及您想展示的任何爱好项目，您可以轻松免费托管它们。最佳位置和最佳方式随时间而变化，因此请查看本书网站以获取最新的建议。由于我们在 2020 年初撰写本书，最简单（且免费！）的方法是使用Binder。要在 Binder 上发布您的 Web 应用程序，请按照以下步骤操作：\n\n将您的笔记本添加到GitHub 存储库。\n\n将该存储库的 URL 粘贴到 Binder 的 URL 字段中，如图 2-4 所示。\n\n将文件下拉菜单更改为选择 URL。\n\n在“要打开的 URL”字段中，输入/voila/render/*name*.ipynb（将name替换为您笔记本的名称）。\n\n单击右下角的剪贴板按钮以复制 URL，并将其粘贴到安全位置。\n\n单击“启动”。\n\n\n\n图 2-4. 部署到 Binder第一次执行此操作时，Binder 将花费大约 5 分钟来构建您的站点。在幕后，它正在查找一个可以运行您的应用程序的虚拟机，分配存储空间，并收集所需的文件以用于 Jupyter、您的笔记本以及将您的笔记本呈现为 Web 应用程序。\n最后，一旦启动应用程序运行，它将导航您的浏览器到您的新 Web 应用程序。您可以分享您复制的 URL 以允许其他人访问您的应用程序。\n要了解部署 Web 应用程序的其他（免费和付费）选项，请务必查看书籍网站。\n您可能希望将应用程序部署到移动设备或边缘设备，如树莓派。有许多库和框架允许您将模型直接集成到移动应用程序中。但是，这些方法往往需要许多额外的步骤和样板文件，并且并不总是支持您的模型可能使用的所有 PyTorch 和 fastai 层。此外，您所做的工作将取决于您针对部署的移动设备的类型 - 您可能需要做一些工作以在 iOS 设备上运行，不同的工作以在较新的 Android 设备上运行，不同的工作以在较旧的 Android 设备上运行，等等。相反，我们建议在可能的情况下，将模型本身部署到服务器，并让您的移动或边缘应用程序连接到它作为 Web 服务。\n这种方法有很多优点。初始安装更容易，因为您只需部署一个小型 GUI 应用程序，该应用程序连接到服务器执行所有繁重的工作。更重要的是，核心逻辑的升级可以在您的服务器上进行，而不需要分发给所有用户。您的服务器将拥有比大多数边缘设备更多的内存和处理能力，并且如果您的模型变得更加苛刻，那么扩展这些资源将更容易。您在服务器上拥有的硬件也将更加标准化，并且更容易受到 fastai 和 PyTorch 的支持，因此您不必将模型编译成不同的形式。\n当然也有缺点。你的应用程序将需要网络连接，每次调用模型时都会有一些延迟。（神经网络模型本来就需要一段时间来运行，所以这种额外的网络延迟在实践中可能对用户没有太大影响。事实上，由于你可以在服务器上使用更好的硬件，总体延迟甚至可能比在本地运行时更少！）此外，如果你的应用程序使用敏感数据，你的用户可能会担心采用将数据发送到远程服务器的方法，因此有时隐私考虑将意味着你需要在边缘设备上运行模型（通过在公司防火墙内部设置本地服务器可能可以避免这种情况）。管理复杂性和扩展服务器也可能会带来额外的开销，而如果你的模型在边缘设备上运行，每个用户都会带来自己的计算资源，这将导致随着用户数量的增加更容易扩展（也称为水平扩展）。\nAlexis 说我有机会近距离看到移动机器学习领域在我的工作中是如何变化的。我们提供一个依赖于计算机视觉的 iPhone 应用程序，多年来我们在云中运行我们自己的计算机视觉模型。那时这是唯一的方法，因为那些模型需要大量的内存和计算资源，并且需要几分钟来处理输入。这种方法不仅需要构建模型（有趣！），还需要构建基础设施来确保一定数量的“计算工作机器”始终在运行（可怕），如果流量增加，更多的机器会自动上线，有稳定的存储用于大型输入和输出，iOS 应用程序可以知道并告诉用户他们的工作进展如何等等。如今，苹果提供了 API，可以将模型转换为在设备上高效运行，大多数 iOS 设备都有专用的 ML 硬件，所以这是我们用于新模型的策略。这仍然不容易，但在我们的情况下，为了更快的用户体验和更少地担心服务器，这是值得的。对你来说有效的方法将取决于你试图创建的用户体验以及你个人认为容易做的事情。如果你真的知道如何运行服务器，那就去做。如果你真的知道如何构建本地移动应用程序，那就去做。有很多条路通往山顶。\n总的来说，我们建议在可能的情况下尽可能使用简单的基于 CPU 的服务器方法，只要你能够做到。如果你足够幸运拥有一个非常成功的应用程序，那么你将能够在那个时候为更复杂的部署方法进行投资。\n恭喜你——你已经成功构建了一个深度学习模型并部署了它！现在是一个很好的时机停下来思考可能出现的问题。\n如何避免灾难在实践中，一个深度学习模型只是一个更大系统中的一部分。正如我们在本章开头讨论的那样，构建数据产品需要考虑整个端到端的过程，从概念到在生产中使用。在这本书中，我们无法希望涵盖所有管理部署数据产品的复杂性，比如管理多个模型版本，A/B 测试，金丝雀发布，刷新数据（我们应该一直增加和增加我们的数据集，还是应该定期删除一些旧数据？），处理数据标记，监控所有这些，检测模型腐烂等等。\n在本节中，我们将概述一些需要考虑的最重要问题；关于部署问题的更详细讨论，我们建议您参考 Emmanuel Ameisin（O’Reilly）的优秀著作《构建机器学习驱动的应用程序》。\n需要考虑的最大问题之一是，理解和测试深度学习模型的行为比大多数其他代码更困难。在正常软件开发中，您可以分析软件所采取的确切步骤，并仔细研究这些步骤中哪些与您试图创建的期望行为相匹配。但是，对于神经网络，行为是从模型尝试匹配训练数据中产生的，而不是精确定义的。\n这可能导致灾难！例如，假设我们真的正在推出一个熊检测系统，将连接到国家公园露营地周围的视频摄像头，并警告露营者有熊靠近。如果我们使用下载的数据集训练的模型，实际上会出现各种问题，比如：\n\n处理视频数据而不是图像\n\n处理可能不在数据集中出现的夜间图像\n\n处理低分辨率摄像头图像\n\n确保结果返回得足够快以在实践中有用\n\n在照片中很少见到的位置识别熊（例如从背后，部分被灌木覆盖，或者离摄像机很远）\n\n\n问题的一个重要部分是，人们最有可能上传到互联网的照片是那些能够清晰艺术地展示主题的照片，而这并不是该系统将获得的输入类型。因此，我们可能需要进行大量自己的数据收集和标记以创建一个有用的系统。\n这只是更一般的“域外”数据问题的一个例子。也就是说，在生产中，我们的模型可能看到与训练时非常不同的数据。这个问题没有完全的技术解决方案；相反，我们必须谨慎地推出技术。\n我们还需要小心的其他原因。一个非常常见的问题是域漂移，即我们的模型看到的数据类型随着时间的推移而发生变化。例如，一个保险公司可能将深度学习模型用作其定价和风险算法的一部分，但随着时间的推移，公司吸引的客户类型和代表的风险类型可能发生如此大的变化，以至于原始训练数据不再相关。\n域外数据和域漂移是更大问题的例子：您永远无法完全理解神经网络的所有可能行为，因为它们有太多参数。这是它们最好特性的自然缺点——它们的灵活性，使它们能够解决我们甚至可能无法完全指定首选解决方案的复杂问题。然而，好消息是，有办法通过一个经过深思熟虑的过程来减轻这些风险。这些细节将根据您正在解决的问题的细节而变化，但我们将尝试提出一个高层次的方法，总结在图 2-5 中，我们希望这将提供有用的指导。\n\n杰里米说20 年前，我创办了一家名为 Optimal Decisions 的公司，利用机器学习和优化帮助巨大的保险公司设定价格，影响数千亿美元的风险。我们使用这里描述的方法来管理可能出错的潜在风险。此外，在与客户合作将任何东西投入生产之前，我们尝试通过在他们去年的数据上测试端到端系统的影响来模拟影响。将这些新算法投入生产总是一个非常紧张的过程，但每次推出都取得了成功。\n意想不到的后果和反馈循环推出模型的最大挑战之一是，您的模型可能会改变其所属系统的行为。例如，考虑一个“预测执法”算法，它预测某些社区的犯罪率更高，导致更多警察被派往这些社区，这可能导致这些社区记录更多犯罪，依此类推。在皇家统计学会的论文“预测和服务？”中，Kristian Lum 和 William Isaac 观察到“预测性执法的命名恰如其分：它预测未来的执法，而不是未来的犯罪。”\n在这种情况下的部分问题是，在存在偏见的情况下（我们将在下一章中深入讨论），反馈循环可能导致该偏见的负面影响变得越来越严重。例如，在美国已经存在着在种族基础上逮捕率存在显著偏见的担忧。根据美国公民自由联盟的说法，“尽管使用率大致相等，黑人因大麻被逮捕的可能性是白人的 3.73 倍。”这种偏见的影响，以及在美国许多地区推出预测性执法算法，导致 Bärí Williams 在纽约时报中写道：“在我的职业生涯中引起如此多兴奋的技术正在以可能意味着在未来几年，我的 7 岁儿子更有可能因为他的种族和我们居住的地方而被无故定性或逮捕，甚至更糟。”\n在推出重要的机器学习系统之前，一个有用的练习是考虑这个问题：“如果它真的很成功会发生什么？”换句话说，如果预测能力非常高，对行为的影响非常显著，那么会发生什么？谁会受到最大影响？最极端的结果可能是什么样的？你怎么知道到底发生了什么？\n这样的思考练习可能会帮助你制定一个更加谨慎的推出计划，配备持续监控系统和人类监督。当然，如果人类监督没有被听取，那么它就没有用，因此确保可靠和有弹性的沟通渠道存在，以便正确的人会意识到问题并有权力解决它们。\n课后练习\n文本模型目前存在哪些主要不足之处？\n\n\n深度学习不擅长生成正确的回应！\n\n\n文本生成模型可能存在哪些负面社会影响？\n\n\n用来传播虚假消息，鼓动不安情绪，或者是骗你钱骗你感情哈哈哈哈（因为现在你快已经无法分辨出你在和人类聊天还是深度学习机器人）\n\n\n在模型可能犯错且这些错误可能有害的情况下，自动化流程的一个好的替代方案是什么？\n\n\n由于这个严重问题，我们通常建议深度学习不要作为完全自动化的过程，而是作为模型和人类用户密切互动的过程的一部分。这可能使人类的生产力比完全手动方法高出几个数量级，并且比仅使用人类更准确。深度学习模型现在仅仅是人类可以用来参考的工具而非你问就给你答案的神灯\n\n\n深度学习在哪种表格数据上特别擅长？\n\n\n包含自然语言（书名、评论等）和高基数分类列（即包含大量离散选择的内容，如邮政编码或产品 ID）。关于随机森林或梯度提升的表格（数据类型）就需要花更长的时间训练了。\n\n\n直接使用深度学习模型进行推荐系统的一个主要缺点是什么？\n\n\n他会推荐对你无用的产品或者你已经知道的东西，比如你已经买了某个东西他还是会给你推荐。\n\n\n驱动器方法的步骤是什么？\n\n\n定义一个明确的目标\n可以采取的行动\n需要什么新数据来生成这样的排名\n构建预测模型\n构建多个模型，比较差异\n\n\n驱动器方法的步骤如何映射到推荐系统？\n\n\n推荐引擎的目标是通过推荐客户不会在没有推荐的情况下购买的物品来推动额外的销售。杠杆是推荐的排名。必须收集新数据以生成将导致新销售的推荐。这将需要进行许多随机实验，以收集关于各种客户的各种推荐的数据。这是很少有组织采取的一步；但是没有它，您就没有所需的信息来根据您的真正目标（更多销售！）优化推荐。\n\n最后，您可以为购买概率构建两个模型，条件是看到或没有看到推荐。这两个概率之间的差异是给定推荐给客户的效用函数。在算法推荐客户已经拒绝的熟悉书籍（两个组成部分都很小）或者他们本来就会购买的书籍（两个组成部分都很大并互相抵消）的情况下，效用函数会很低。\n\n\n\n使用你策划的数据创建一个图像识别模型，并将其部署在网络上。（还未成功因为获取数据集api的问题）\n\nDataLoaders是什么？\n\n\n\n一个 fastai 类，存储您传递给它的多个DataLoader对象——通常是一个train和一个valid，尽管可以有任意数量。前两个作为属性提供。\n\n\n我们需要告诉 fastai 创建DataLoaders的四件事是什么？\n\n\n我们正在处理什么类型的数据\n\n如何获取项目列表\n\n如何为这些项目打标签\n\n如何创建验证集\n\n\n\nDataBlock中的splitter参数是做什么的？\n\n\n用来在数据集中分出训练集和验证集（设定验证集比率valid_pct和起始点seed）\n\n\n我们如何确保随机分割总是给出相同的验证集？\n\n\n保证比率valid_pct和起始点seed一致即可\n\n\n哪些字母通常用来表示自变量和因变量？\n\n\n自变量通常被称为x，因变量通常被称为y。在这里，我们告诉 fastai 要调用哪个函数来创建数据集中的标签：\n\nget_y=parent_label\n\n裁剪、填充和压缩调整方法之间有什么区别？在什么情况下你会选择其中之一？\n\n\n如果我们压缩或拉伸图像，它们最终会变成不现实的形状，导致模型学习到事物看起来与实际情况不同，这会导致更低的准确性。\n\n如果我们裁剪图像，我们会移除一些允许我们进行识别的特征。例如，如果我们试图识别狗或猫的品种，我们可能会裁剪掉区分相似品种所需的身体或面部的关键部分。\n\n如果我们填充图像，就会有很多空白空间，这对我们的模型来说只是浪费计算，并导致我们实际使用的图像部分具有较低的有效分辨率。\n\n\n\n什么是数据增强？为什么需要它？\n\n\n数据增强指的是创建输入数据的随机变化，使它们看起来不同但不改变数据的含义。对于图像的常见数据增强技术包括旋转、翻转、透视变形、亮度变化和对比度变化。\n\n一个完全未经训练的神经网络对图像的行为一无所知。它甚至不认识当一个物体旋转一度时，它仍然是同一物体的图片！因此，通过训练神经网络使用物体在略有不同位置并且大小略有不同的图像的示例，有助于它理解物体的基本概念，以及如何在图像中表示它。所以需要图像增强进行训练\n\n\n\n提供一个例子，说明熊分类模型在生产中可能因训练数据的结构或风格差异而效果不佳。\n\n\n文中例子\n\n\nitem_tfms和batch_tfms之间有什么区别？\n\n\n图像现在都是相同大小，我们可以使用 GPU 将这些增强应用于整个批次的图像，这将节省大量时间。要告诉 fastai 我们要在批次上使用这些变换，我们使用batch_tfms参数（请注意，在此示例中我们没有使用RandomResizedCrop，这样您可以更清楚地看到差异；出于同样的原因，我们使用了默认值的两倍的增强量）\n\n我们需要添加一个转换，将这些图像调整为相同的大小。Item transforms是在每个单独项目上运行的代码片段，无论是图像、类别还是其他\n\n\n\n混淆矩阵是什么？\n\n\n行代表数据集中所有黑色、灰熊和泰迪熊，列分别代表模型预测为黑色、灰熊和泰迪熊的图像。因此，矩阵的对角线显示了被正确分类的图像，而非对角线的单元格代表被错误分类的图像。这是 fastai 允许您查看模型结果的许多方式之一。当然，这是使用验证集计算的。通过颜色编码，目标是在对角线以外的地方都是白色，而在对角线上我们希望是深蓝色。我们的熊分类器几乎没有犯错！\n\n看到我们的错误发生在哪里是有帮助的，以便确定它们是由数据集问题（例如，根本不是熊的图像，或者标记错误）还是模型问题（也许它无法处理使用不同光照或从不同角度拍摄的图像等）。为了做到这一点，我们可以根据损失对图像进行排序。\n损失是一个数字，如果模型不正确（尤其是如果它对其不正确的答案也很自信），或者如果它是正确的但对其正确答案不自信，那么损失就会更高。在第二部分的开头，我们将深入学习损失是如何计算和在训练过程中使用的。现在，plot_top_losses向我们展示了数据集中损失最高的图像。正如输出的标题所说，每个图像都标有四个内容：预测、实际（目标标签）、损失和概率。这里的概率是模型对其预测分配的置信水平，从零到一：\ninterp = ClassificationInterpretation.from_learner(learn)interp.plot_confusion_matrix()\n\n\nexport保存了什么？\n\n\n当您调用export时，fastai 将保存一个名为export.pkl的文件其中包含架构和参数\n\n\n当我们使用模型进行预测而不是训练时，这被称为什么？\n\n\n当我们使用模型进行预测而不是训练时，我们称之为推理。\n\n\nIPython 小部件是什么？\n\n\nIPython 小部件是 GUI 组件，它在 Web 浏览器中将 JavaScript 和 Python 功能结合在一起，并可以在 Jupyter 笔记本中创建和使用。例如，我们在本章前面看到的图像清理器完全是用 IPython 小部件编写的。但是，我们不希望要求我们的应用程序用户自己运行 Jupyter。\n\n\n什么时候会使用 CPU 进行部署？什么时候 GPU 可能更好？\n\n\n几乎任何有用的深度学习模型都需要 GPU 来训练。那么，在生产中使用该模型需要 GPU 吗？不需要！您几乎可以肯定在生产中不需要 GPU 来提供您的模型。这样做有几个原因：\n\n正如我们所见，GPU 仅在并行执行大量相同工作时才有用。如果您正在进行（比如）图像分类，通常一次只会对一个用户的图像进行分类，而且通常在一张图像中没有足够的工作量可以让 GPU 忙碌足够长的时间以使其非常有效。因此，CPU 通常更具成本效益。\n\n另一种选择可能是等待一些用户提交他们的图像，然后将它们批量处理并一次性在 GPU 上处理。但是这样会让用户等待，而不是立即得到答案！而且您需要一个高流量的网站才能实现这一点。如果您确实需要这种功能，您可以使用诸如 Microsoft 的ONNX Runtime或AWS SageMaker之类的工具。\n\n处理 GPU 推理的复杂性很大。特别是，GPU 的内存需要仔细手动管理，您需要一个仔细的排队系统，以确保一次只处理一个批次。\n\nCPU 服务器的市场竞争要比 GPU 服务器更激烈，因此 CPU 服务器有更便宜的选项可供选择。\n\n\n\n将应用部署到服务器而不是客户端（或边缘）设备（如手机或 PC）的缺点是什么？\n\n\n你的应用程序将需要网络连接，每次调用模型时都会有一些延迟。\n\n\n在实践中推出熊警告系统时可能出现的三个问题的例子是什么？\n\n\n处理视频数据而不是图像\n\n处理可能不在数据集中出现的夜间图像\n\n处理低分辨率摄像头图像\n\n确保结果返回得足够快以在实践中有用\n\n在照片中很少见到的位置识别熊（例如从背后，部分被灌木覆盖，或者离摄像机很远）\n\n\n\n什么是域外数据？\n\n\n人们最有可能上传到互联网的照片是那些能够清晰艺术地展示主题的照片，而这并不是该系统将获得的输入类型。因此，我们可能需要进行大量自己的数据收集和标记以创建一个有用的系统。\n\n这只是更一般的“域外”数据问题的一个例子。也就是说，在生产中，我们的模型可能看到与训练时非常不同的数据。这个问题没有完全的技术解决方案；相反，我们必须谨慎地推出技术。\n\n\n\n什么是领域转移？\n\n\n即我们的模型看到的数据类型随着时间的推移而发生变化。例如，一个保险公司可能将深度学习模型用作其定价和风险算法的一部分，但随着时间的推移，公司吸引的客户类型和代表的风险类型可能发生如此大的变化，以至于原始训练数据不再相关。\n\n\n部署过程中的三个步骤是什么？\n\n\n第一步是使用完全手动的过程\n\n第二步是尝试限制模型的范围\n\n逐渐扩大您的推出范围\n\n\n进一步研究\n考虑一下驱动器方法如何映射到你感兴趣的项目或问题。\n\n在什么情况下最好避免某些类型的数据增强？\n\n对于你有兴趣应用深度学习的项目，考虑一下这个思维实验，“如果它进展得非常顺利会发生什么？”\n\n开始写博客，撰写你的第一篇博客文章。例如，写一下你认为深度学习在你感兴趣的领域可能有用的地方。\n\n\n","tags":["Machine Learning  Deep Learning"]},{"title":"Fastai Chapter 4","url":"/2025/04/28/fastaichapter4/","content":"第四章：底层：训练数字分类器在第二章中看到训练各种模型的样子后，现在让我们深入了解并看看究竟发生了什么。我们将使用计算机视觉来介绍深度学习的基本工具和概念。\n确切地说，我们将讨论数组和张量的作用以及广播的作用，这是一种使用它们表达性地的强大技术。我们将解释随机梯度下降（SGD），这是通过自动更新权重学习的机制。我们将讨论基本分类任务的损失函数的选择，以及小批量的作用。我们还将描述基本神经网络正在执行的数学。最后，我们将把所有这些部分组合起来。\n在未来的章节中，我们还将深入研究其他应用，并看看这些概念和工具如何泛化。但本章是关于奠定基础的。坦率地说，这也使得这是最困难的章节之一，因为这些概念彼此相互依赖。就像一个拱门，所有的石头都需要放在正确的位置才能支撑结构。也像一个拱门，一旦发生这种情况，它就是一个强大的结构，可以支撑其他事物。但是需要一些耐心来组装。\n让我们开始吧。第一步是考虑图像在计算机中是如何表示的。\n像素：计算机视觉的基础要理解计算机视觉模型中发生的事情，我们首先必须了解计算机如何处理图像。我们将使用计算机视觉中最著名的数据集之一 MNIST 进行实验。MNIST 包含由国家标准与技术研究所收集的手写数字图像，并由 Yann Lecun 及其同事整理成一个机器学习数据集。Lecun 在 1998 年使用 MNIST 在 LeNet-5 中，这是第一个演示实用手写数字序列识别的计算机系统。这是人工智能历史上最重要的突破之一。\n对于这个初始教程，我们只是尝试创建一个模型，可以将任何图像分类为 3 或 7。所以让我们下载一个包含这些数字图像的 MNIST 样本：\npath = untar_data(URLs.MNIST_SAMPLE)\n我们可以使用ls来查看此目录中的内容，这是 fastai 添加的一个方法。这个方法返回一个特殊的 fastai 类L的对象，它具有 Python 内置list的所有功能，还有更多功能。其中一个方便的功能是，在打印时，它会显示项目的计数，然后列出项目本身（如果项目超过 10 个，它只显示前几个）：\npath.ls()\n(#9) [Path(&#x27;cleaned.csv&#x27;),Path(&#x27;item_list.txt&#x27;),Path(&#x27;trained_model.pkl&#x27;),Path(&#x27; &gt; models&#x27;),Path(&#x27;valid&#x27;),Path(&#x27;labels.csv&#x27;),Path(&#x27;export.pkl&#x27;),Path(&#x27;history.cs &gt; v&#x27;),Path(&#x27;train&#x27;)]\nMNIST 数据集遵循机器学习数据集的常见布局：训练集和验证（和/或测试）集分开存放。让我们看看训练集中的内容：\n(path/&#x27;train&#x27;).ls()\n(#2) [Path(&#x27;train/7&#x27;),Path(&#x27;train/3&#x27;)]\n有一个包含 3 的文件夹，和一个包含 7 的文件夹。在机器学习术语中，我们说“3”和“7”是这个数据集中的标签（或目标）。让我们看看其中一个文件夹中的内容（使用sorted确保我们都得到相同的文件顺序）：\nthrees = (path/&#x27;train&#x27;/&#x27;3&#x27;).ls().sorted()sevens = (path/&#x27;train&#x27;/&#x27;7&#x27;).ls().sorted()threes\n(#6131) [Path(&#x27;train/3/10.png&#x27;),Path(&#x27;train/3/10000.png&#x27;),Path(&#x27;train/3/10011.pn &gt; g&#x27;),Path(&#x27;train/3/10031.png&#x27;),Path(&#x27;train/3/10034.png&#x27;),Path(&#x27;train/3/10042.p &gt; ng&#x27;),Path(&#x27;train/3/10052.png&#x27;),Path(&#x27;train/3/1007.png&#x27;),Path(&#x27;train/3/10074.p &gt; ng&#x27;),Path(&#x27;train/3/10091.png&#x27;)...]\n正如我们所预期的那样，它充满了图像文件。让我们现在看一个。这是一个手写数字 3 的图像，来自著名的手写数字 MNIST 数据集：\nim3_path = threes[1]im3 = Image.open(im3_path)im3\n\n在这里，我们使用Python Imaging Library（PIL）中的Image类，这是最广泛使用的 Python 包，用于打开、操作和查看图像。Jupyter 知道 PIL 图像，所以它会自动为我们显示图像。\n在计算机中，一切都以数字表示。要查看构成这幅图像的数字，我们必须将其转换为NumPy 数组或PyTorch 张量。例如，这是转换为 NumPy 数组后图像的一部分的样子：\narray(im3)[4:10,4:10]\narray([[  0,   0,   0,   0,   0,   0],       [  0,   0,   0,   0,   0,  29],       [  0,   0,   0,  48, 166, 224],       [  0,  93, 244, 249, 253, 187],       [  0, 107, 253, 253, 230,  48],       [  0,   3,  20,  20,  15,   0]], dtype=uint8)\n4:10表示我们请求从索引 4（包括）到 10（不包括）的行，列也是一样。NumPy 从上到下，从左到右索引，因此此部分位于图像的左上角附近。这里是一个 PyTorch 张量：\ntensor(im3)[4:10,4:10]\ntensor([[  0,   0,   0,   0,   0,   0],        [  0,   0,   0,   0,   0,  29],        [  0,   0,   0,  48, 166, 224],        [  0,  93, 244, 249, 253, 187],        [  0, 107, 253, 253, 230,  48],        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)\n4:10表示我们请求从索引 4（包括）到 10（不包括）的行，列也是一样。NumPy 从上到下，从左到右索引，因此此部分位于图像的左上角附近。这里是一个 PyTorch 张量：\ntensor(im3)[4:10,4:10]\ntensor([[  0,   0,   0,   0,   0,   0],        [  0,   0,   0,   0,   0,  29],        [  0,   0,   0,  48, 166, 224],        [  0,  93, 244, 249, 253, 187],        [  0, 107, 253, 253, 230,  48],        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)\n我们可以切片数组，只选择包含数字顶部部分的部分，然后使用 Pandas DataFrame 使用渐变对值进行着色，这清楚地显示了图像是如何由像素值创建的：\nim3_t = tensor(im3)df = pd.DataFrame(im3_t[4:15,4:22])df.style.set_properties(**&#123;&#x27;font-size&#x27;:&#x27;6pt&#x27;&#125;).background_gradient(&#x27;Greys&#x27;)\n\n你可以看到，背景白色像素存储为数字 0，黑色为数字 255，灰色在两者之间。整个图像横向包含 28 个像素，纵向包含 28 个像素，总共 768 个像素。（这比你从手机相机得到的图像要小得多，手机相机有数百万像素，但对于我们的初始学习和实验来说，这是一个方便的大小。我们将很快构建更大的全彩图像。）\n所以，现在你已经看到了计算机对图像的看法，让我们回顾一下我们的目标：创建一个能够识别 3 和 7 的模型。你会如何让计算机做到这一点呢？\n停下来思考！在继续阅读之前，花点时间考虑一下计算机可能如何识别这两个数字。它可能能够看到什么样的特征？它可能如何识别这些特征？它如何将它们结合起来？学习最好的方式是尝试自己解决问题，而不仅仅是阅读别人的答案；所以离开这本书几分钟，拿一张纸和笔，写下一些想法。\n 我认为计算机可能会用识别到的手写数字图像的矩阵和标准的数字图像的矩阵进行运算像是点乘或是什么得出一个能给表现图片数字和标准数字相似度的一个数值进行比较取得最大的为识别数字。\n\n第一次尝试：像素相似度所以，这是一个第一个想法：我们可以找到每个 3 的像素的平均值，然后对 7 做同样的操作。这将给我们两组平均值，定义了我们可能称之为“理想”3 和 7。然后，为了将图像分类为一个数字或另一个数字，我们看看这两个理想数字中图像与哪个更相似。这肯定似乎比没有好，所以这将成为一个很好的基线。\n术语：基线一个简单的模型，你有信心应该表现得相当不错。它应该简单实现和易于测试，这样你就可以测试每个改进的想法，并确保它们始终优于基线。如果没有以合理的基线开始，很难知道你的超级花哨的模型是否好用。创建基线的一个好方法是做我们在这里做的事情：考虑一个简单、易于实现的模型。另一个好方法是四处寻找解决类似问题的其他人，并在你的数据集上下载并运行他们的代码。最好两者都尝试一下！\n我们简单模型的第一步是获取我们两组像素值的平均值。在这个过程中，我们将学习很多有趣的 Python 数值编程技巧！\n让我们创建一个包含所有 3 的张量堆叠在一起。我们已经知道如何创建包含单个图像的张量。要创建一个包含目录中所有图像的张量，我们将首先使用 Python 列表推导来创建一个单个图像张量的普通列表。\n我们将使用 Jupyter 在途中做一些小的检查——在这种情况下，确保返回的项目数量看起来合理：\nseven_tensors = [tensor(Image.open(o)) for o in sevens]three_tensors = [tensor(Image.open(o)) for o in threes]len(three_tensors),len(seven_tensors)\n(6131, 6265)\n列表推导列表和字典推导是 Python 的一个很棒的特性。许多 Python 程序员每天都在使用它们，包括本书的作者们——它们是“Python 的成语”。但是来自其他语言的程序员可能以前从未见过它们。许多很棒的教程只需一次网络搜索，所以我们现在不会花很长时间讨论它们。这里有一个快速的解释和示例，让您开始。列表推导看起来像这样：new_list = [f(o) for o in a_list if o&gt;0]。这将返回a_list中大于 0 的每个元素，在将其传递给函数f之后。这里有三个部分：您正在迭代的集合（a_list），一个可选的过滤器（if o&gt;0），以及对每个元素执行的操作（f(o)）。不仅写起来更短，而且比用循环创建相同列表的替代方法更快。\n我们还将检查其中一张图像是否正常。由于我们现在有张量（Jupyter 默认会将其打印为值），而不是 PIL 图像（Jupyter 默认会显示图像），我们需要使用 fastai 的show_image函数来显示它：\nshow_image(three_tensors[1]);\n\n对于每个像素位置，我们想要计算该像素的强度在所有图像上的平均值。为了做到这一点，我们首先将此列表中的所有图像组合成一个三维张量。描述这样的张量最常见的方式是称之为rank-3 张量。我们经常需要将集合中的单个张量堆叠成一个张量。不出所料，PyTorch 带有一个名为stack的函数，我们可以用它来实现这个目的。\nPyTorch 中的一些操作，如取平均值，需要我们将整数类型转换为浮点类型。由于我们稍后会需要这个，我们现在也将我们的堆叠张量转换为float。在 PyTorch 中进行转换就像写下您希望转换为的类型名称，并将其视为方法一样简单。\n通常，当图像是浮点数时，像素值应该在 0 到 1 之间，所以我们也会在这里除以 255：\nstacked_sevens = torch.stack(seven_tensors).float()/255stacked_threes = torch.stack(three_tensors).float()/255stacked_threes.shape\ntorch.Size([6131, 28, 28])\n张量最重要的属性也许是其形状。这告诉您每个轴的长度。在这种情况下，我们可以看到我们有 6,131 张图像，每张图像大小为 28×28 像素。关于这个张量没有特别的地方表明第一个轴是图像的数量，第二个是高度，第三个是宽度——张量的语义完全取决于我们以及我们如何构建它。就 PyTorch 而言，它只是内存中的一堆数字。\n张量形状的长度是其秩：\nlen(stacked_threes.shape)\n3\n对于您来说，将张量术语的这些部分记忆并加以实践非常重要：秩是张量中轴或维度的数量；形状是张量每个轴的大小。\n关于维度要小心，因为术语“维度”有时以两种方式使用。考虑我们生活在“三维空间”中，其中物理位置可以用长度为 3 的向量v描述。但根据 PyTorch，属性v.ndim（看起来确实像v的“维度数量”）等于一，而不是三！为什么？因为v是一个向量，它是一个秩为一的张量，这意味着它只有一个轴（即使该轴的长度为三）。换句话说，有时维度用于描述轴的大小（“空间是三维的”），而其他时候用于描述秩或轴的数量（“矩阵有两个维度”）。当感到困惑时，我发现将所有陈述转换为秩、轴和长度这些明确的术语是有帮助的。\n我们也可以直接使用ndim来获取张量的秩：\nstacked_threes.ndim\n3\n最后，我们可以计算理想的 3 是什么样子的。我们通过沿着我们堆叠的 rank-3 张量的维度 0 取平均值来计算所有图像张量的平均值。这是索引所有图像的维度。\n换句话说，对于每个像素位置，这将计算所有图像中该像素的平均值。结果将是每个像素位置的一个值，或者一个单独的图像。这就是它：\nmean3 = stacked_threes.mean(0)show_image(mean3);\n\n根据这个数据集，这是理想的数字 3！（您可能不喜欢，但这就是顶级数字 3 表现的样子。）您可以看到在所有图像都认为应该是暗的地方非常暗，但在图像不一致的地方变得模糊。\n让我们对 7 做同样的事情，但一次将所有步骤放在一起以节省时间：\nmean7 = stacked_sevens.mean(0)show_image(mean7);\n\n现在让我们选择一个任意的 3，并测量它与我们的“理想数字”的距离。\n停下来思考一下！您如何计算特定图像与我们的每个理想数字之间的相似程度？在继续前进之前，请记得远离这本书，记录一些想法！研究表明，通过解决问题、实验和尝试新想法，您参与学习过程时，召回和理解会显著提高。\n这是一个示例 3：\na_3 = stacked_threes[1]show_image(a_3);\n\n我们如何确定它与我们理想的 3 之间的距离？我们不能简单地将此图像的像素之间的差异相加，并与理想数字进行比较。一些差异将是正的，而另一些将是负的，这些差异将相互抵消，导致一种情况，即在某些地方太暗而在其他地方太亮的图像可能被显示为与理想的总差异为零。那将是误导性的！\n为了避免这种情况，数据科学家在这种情况下使用两种主要方法来测量距离：\n\n取差值的绝对值的平均值（绝对值是将负值替换为正值的函数）。这被称为平均绝对差或L1 范数。\n\n取差值的平方的平均值（使所有值变为正数），然后取平方根（撤销平方）。这被称为均方根误差（RMSE）或L2 范数。\n\n\n在pytorch中 取差值的绝对值的平均值（绝对值是将负值替换为正值的函数）。这被称为平均绝对差或L1 范数。dist_7_abs = (a_3 - mean7).abs().mean()dist_7_sqr = ((a_3 - mean7)**2).mean().sqrt()dist_7_abs,dist_7_sqr\n(tensor(0.1586), tensor(0.3021))\n等同于：\nPyTorch 已经提供了这两种作为损失函数。您会在torch.nn.functional中找到这些，PyTorch 团队建议将其导入为F（并且默认情况下以这个名称在 fastai 中可用）：\nF.l1_loss(a_3.float(),mean7), F.mse_loss(a_3,mean7).sqrt()\n(tensor(0.1586), tensor(0.3021))\n在这里，MSE代表均方误差，l1是标准数学术语平均绝对值的缩写（在数学中称为L1 范数）。\nL1 范数和 均方误差（MSE）之间的区别直观地，L1 范数和均方误差（MSE）之间的区别在于，后者会比前者更严厉地惩罚更大的错误（并对小错误更宽容）。\n"},{"title":"Fastai Chapter 1","url":"/2025/04/22/pytorch/","content":"什么是机器学习？你的分类器是一个深度学习模型。正如已经提到的，深度学习模型使用神经网络，这些神经网络最初可以追溯到上世纪 50 年代，并且最近由于最新的进展变得非常强大。\n另一个重要的背景是，深度学习只是更一般的机器学习领域中的一个现代领域。要理解当你训练自己的分类模型时所做的事情的本质，你不需要理解深度学习。看到你的模型和训练过程是如何成为适用于机器学习的概念的例子就足够了。\n因此，在本节中，我们将描述机器学习。我们将探讨关键概念，并看看它们如何可以追溯到最初介绍它们的原始文章。\n机器学习就像常规编程一样，是让计算机完成特定任务的一种方式。但是如果要用常规编程来完成前面部分我们刚刚做的事情：在照片中识别狗和猫，我们将不得不为计算机写下完成任务所需的确切步骤。\n通常，当我们编写程序时，很容易为我们写下完成任务的步骤。我们只需考虑如果我们必须手动完成任务时会采取的步骤，然后将它们转换为代码。例如，我们可以编写一个对列表进行排序的函数。一般来说，我们会编写一个类似于图 1-4 的函数（其中inputs可能是一个未排序的列表，results是一个排序后的列表）。\n\n图 1-4. 传统程序但是要在照片中识别物体，这有点棘手；当我们在图片中识别物体时，我们采取了什么步骤？我们真的不知道，因为这一切都发生在我们的大脑中，而我们并没有意识到！\n早在计算机诞生之初，1949 年，IBM 的一位研究员阿瑟·塞缪尔开始研究一种让计算机完成任务的不同方式，他称之为机器学习。在他经典的 1962 年文章“人工智能：自动化的前沿”中，他写道：\n\n为这样的计算编程对于我们来说是相当困难的，主要不是因为计算机本身的任何固有复杂性，而是因为需要详细说明过程的每一个细微步骤。任何程序员都会告诉你，计算机是巨大的白痴，而不是巨大的大脑。\n\n他的基本想法是这样的：不是告诉计算机解决问题所需的确切步骤，而是向其展示解决问题的示例，并让它自己找出如何解决。结果证明这非常有效：到 1961 年，他的跳棋程序学到了很多，以至于击败了康涅狄格州冠军！这是他描述自己想法的方式（与之前提到的同一篇文章）：\n\n假设我们安排一些自动手段来测试任何当前权重分配的有效性，以实际表现为准，并提供一种机制来改变权重分配以最大化性能。我们不需要详细了解这种程序的细节，就可以看到它可以完全自动化，并且可以看到一个这样编程的机器将从中学习。\n\n这个简短陈述中嵌入了一些强大的概念：\n\n“权重分配”的想法\n\n每个权重分配都有一些“实际表现”的事实\n\n要求有一种“自动手段”来测试该性能\n\n需要一个“机制”（即，另一个自动过程）来通过改变权重分配来提高性能\n\n\n让我们逐一了解这些概念，以便了解它们在实践中如何结合。首先，我们需要了解塞缪尔所说的权重分配是什么意思。\n权重只是变量，权重分配是这些变量的特定值选择。程序的输入是它处理以产生结果的值，例如，将图像像素作为输入，并返回分类“狗”作为结果。程序的权重分配是定义程序操作方式的其他值。\n因为它们会影响程序，它们在某种意义上是另一种输入。我们将更新我们的基本图片图 1-4，并用图 1-5 替换，以便考虑到这一点。\n\n图 1-5。使用权重分配的程序我们已将方框的名称从程序更改为模型。这是为了遵循现代术语并反映模型是一种特殊类型的程序：它可以根据权重做许多不同的事情。它可以以许多不同的方式实现。例如，在塞缪尔的跳棋程序中，不同的权重值会导致不同的跳棋策略。\n（顺便说一句，塞缪尔所说的“权重”如今通常被称为模型参数，以防您遇到这个术语。术语权重保留给特定类型的模型参数。）\n接下来，塞缪尔说我们需要一种自动测试任何当前权重分配的有效性的方法，以实际表现为准。在他的跳棋程序中，“实际表现”模型的表现有多好。您可以通过让两个模型相互对战并看哪个通常获胜来自动测试两个模型的表现。\n最后，他说我们需要一种机制来改变权重分配，以最大化性能。例如，我们可以查看获胜模型和失败模型之间的权重差异，并将权重进一步调整到获胜方向。\n我们现在可以看到他为什么说这样的程序可以完全自动化，并且…一个这样编程的机器将从中学习。当权重的调整也是自动的时，学习将变得完全自动——当我们不再通过手动调整权重来改进模型，而是依赖于根据性能产生调整的自动化机制时。\n图 1-6 展示了塞缪尔关于训练机器学习模型的完整图景。\n！基本训练循环\n\n图 1-6。训练机器学习模型注意模型的结果（例如，在跳棋游戏中的移动）和其性能（例如，是否赢得比赛，或者赢得比赛的速度）之间的区别。\n还要注意，一旦模型训练好了，也就是说，一旦我们选择了最终的、最好的、最喜欢的权重分配，那么我们可以将权重视为模型的一部分，因为我们不再对它们进行变化。\n因此，实际上在训练后使用模型看起来像图 1-7。\n\n图 1-7。使用训练后的模型作为程序这看起来与我们在图 1-4 中的原始图表相同，只是将程序一词替换为模型。这是一个重要的观点：训练后的模型可以像常规计算机程序一样对待。\n行话：机器学习通过让计算机从经验中学习而不是通过手动编码个别步骤来开发程序的培训。\n什么是神经网络？不难想象跳棋程序的模型可能是什么样子。可能编码了一系列跳棋策略，以及某种搜索机制，然后权重可以变化以决定如何选择策略，在搜索期间关注棋盘的哪些部分等等。但是对于图像识别程序，或者理解文本，或者我们可能想象的许多其他有趣的问题，模型可能是什么样子却一点也不明显。\n我们希望有一种函数，它如此灵活，以至于可以通过调整其权重来解决任何给定问题。令人惊讶的是，这种函数实际上存在！这就是我们已经讨论过的神经网络。也就是说，如果您将神经网络视为数学函数，那么它将是一种极其灵活的函数，取决于其权重。一种称为通用逼近定理的数学证明表明，这种函数在理论上可以解决任何问题，达到任何精度水平。神经网络如此灵活的事实意味着，在实践中，它们通常是一种合适的模型，您可以将精力集中在训练过程上，即找到良好的权重分配。\n但是这个过程呢？人们可以想象，您可能需要为每个问题找到一种新的“机制”来自动更新权重。这将是费力的。我们在这里也希望有一种完全通用的方法来更新神经网络的权重，使其在任何给定任务上都能提高。方便的是，这也存在！\n这被称为随机梯度下降（SGD）。我们将在第四章中详细了解神经网络和 SGD 的工作原理，以及解释通用逼近定理。然而，现在，我们将使用塞缪尔自己的话来说：我们不需要深入了解这样一个过程的细节，就可以看到它可以完全自动化，并且可以看到这样一个机器编程的机器可以从中学习经验。\n杰里米说不要担心；无论是 SGD 还是神经网络，在数学上都不复杂。它们几乎完全依赖于加法和乘法来完成工作（但它们进行了大量的加法和乘法！）。当学生们看到细节时，我们听到的主要反应是：“就是这样吗？”\n换句话说，简而言之，神经网络是一种特殊类型的机器学习模型，它完全符合塞缪尔最初的构想。神经网络之所以特殊，是因为它们非常灵活，这意味着它们可以通过找到正确的权重来解决异常广泛的问题。这是强大的，因为随机梯度下降为我们提供了一种自动找到这些权重值的方法。\n放大后，让我们现在缩小范围，重新审视使用塞缪尔框架解决我们的图像分类问题。\n我们的输入是图像。我们的权重是神经网络中的权重。我们的模型是一个神经网络。我们的结果是由神经网络计算出的值，比如“狗”或“猫”。\n下一个部分是什么，一个自动测试任何当前权重分配的有效性的手段？确定“实际表现”很容易：我们可以简单地将模型的表现定义为其在预测正确答案时的准确性。\n将所有这些放在一起，假设 SGD 是我们更新权重分配的机制，我们可以看到我们的图像分类器是一个机器学习模型，就像 Samuel 所设想的那样。\n一些深度学习术语Samuel 在 1960 年代工作，自那时术语已经发生了变化。以下是我们讨论过的所有部分的现代深度学习术语：\n\n模型的功能形式被称为架构（但要小心—有时人们将模型用作架构的同义词，这可能会让人困惑）。\n\n权重被称为参数。\n\n预测是从独立变量计算出来的，这是不包括标签的数据。\n\n模型的结果被称为预测。\n\n性能的度量被称为损失。\n\n损失不仅取决于预测，还取决于正确的标签（也称为目标或因变量）；例如，“狗”或“猫”。\n\n\n在进行这些更改后，我们在图 1-6 中的图表看起来像图 1-8。\n\n图 1-8. 详细训练循环机器学习固有的限制从这幅图片中，我们现在可以看到关于训练深度学习模型的一些基本事情：\n\n没有数据就无法创建模型。\n\n模型只能学习操作训练数据中看到的模式。\n\n这种学习方法只创建预测，而不是推荐的行动。\n\n仅仅拥有输入数据的示例是不够的；我们还需要为这些数据提供标签（例如，仅有狗和猫的图片不足以训练模型；我们需要为每个图片提供一个标签，说明哪些是狗，哪些是猫）。\n\n\n一般来说，我们已经看到大多数组织声称他们没有足够的数据实际上意味着他们没有足够的带标签数据。如果任何组织有兴趣在实践中使用模型做一些事情，那么他们可能有一些输入数据计划运行他们的模型。并且可能他们已经以其他方式做了一段时间（例如，手动或使用一些启发式程序），因此他们有来自这些过程的数据！例如，放射学实践几乎肯定会有医学扫描的存档（因为他们需要能够检查他们的患者随时间的进展），但这些扫描可能没有包含诊断或干预措施列表的结构化标签（因为放射科医生通常创建自由文本自然语言报告，而不是结构化数据）。在本书中，我们将大量讨论标记方法，因为这在实践中是一个非常重要的问题。\n由于这类机器学习模型只能进行预测（即试图复制标签），这可能导致组织目标与模型能力之间存在显著差距。例如，在本书中，您将学习如何创建一个推荐系统，可以预测用户可能购买的产品。这通常用于电子商务，例如通过显示排名最高的商品来定制主页上显示的产品。但这样的模型通常是通过查看用户及其购买历史（输入）以及他们最终购买或查看的内容（标签）来创建的，这意味着该模型很可能会告诉您关于用户已经拥有或已经了解的产品，而不是他们最有可能对其感兴趣的新产品。这与您当地书店的专家所做的事情大不相同，他们会询问您的口味，然后告诉您您以前从未听说过的作者或系列。\n另一个关键的洞察来自于考虑模型如何与其环境互动。这可能会产生反馈循环，如此处所述：\n\n基于过去的逮捕地点创建了一个预测性执法模型。实际上，这并不是在预测犯罪，而是在预测逮捕，因此部分地只是反映了现有执法过程中的偏见。\n\n然后执法人员可能会使用该模型来决定在哪里集中他们的执法活动，导致这些地区的逮捕增加。\n\n这些额外逮捕的数据将被反馈回去重新训练未来版本的模型。\n\n\n这是一个正反馈循环：模型被使用得越多，数据就变得越有偏见，使模型变得更加有偏见，依此类推。\n反馈循环也可能在商业环境中造成问题。例如，视频推荐系统可能会偏向于推荐由视频最大观看者消费的内容（例如，阴谋论者和极端分子倾向于观看比平均水平更多的在线视频内容），导致这些用户增加他们的视频消费量，进而导致更多这类视频被推荐。我们将在第三章中更详细地讨论这个话题。\n既然你已经看到了理论的基础，让我们回到我们的代码示例，详细看看代码如何与我们刚刚描述的过程相对应。\n代码如何工作让我们看看我们的图像识别器代码如何映射到这些想法。我们将把每一行放入一个单独的单元格，并查看每一行正在做什么（我们暂时不会解释每个参数的每个细节，但会给出重要部分的描述；完整细节将在本书后面提供）。第一行导入了整个 fastai.vision 库：\nfrom fastai.vision.all import * #第一行导入了整个 fastai.vision 库，*代表导入所有的函数类变量，这通常在常规编程中不出现因为会造成很多的错误。path = untar_data(URLs.PETS)/&#x27;images&#x27;#第二行从[fast.ai 数据集合](https://course.fast.ai/datasets)下载一个标准数据集（如果之前没有下载），将其提取出来（如果之前没有提取），并返回一个提取位置的`Path`对象。def is_cat(x): return x[0].isupper()#定义了一个函数`is_cat`，根据数据集创建者提供的文件名规则来标记猫，猫狗利用文件名大小写区分。dls = ImageDataLoaders.from_name_func(    path, get_image_files(path), valid_pct=0.2, seed=42,    label_func=is_cat, item_tfms=Resize(224))#第四行使用了这个函数，告诉 fastai 我们拥有什么类型的数据集以及它的结构#调用`from_name_func`来实现（这意味着可以使用应用于文件名的函数来提取文件名），并传递`x[0].isupper()`，如果第一个字母是大写字母（即是猫），则评估为`True`。#`valid_pct=0.2`。这告诉 fastai 保留 20%的数据，*完全不用于训练模型*。这 20%的数据被称为*验证集*；剩下的 80%被称为*训练集*。验证集用于衡量模型的准确性。#参数`seed=42`将*随机种子*设置为每次运行此代码时相同的值，这意味着每次运行时我们都会得到相同的验证集，这样，如果我们更改模型并重新训练它，我们知道任何差异都是由于对模型的更改，而不是由于有不同的随机验证集。learn = cnn_learner(dls, resnet34, metrics=error_rate)#第五行告诉 fastai 创建一个*卷积神经网络*（CNN），并指定要使用的*架构*（即要创建的模型类型）、我们要对其进行训练的数据以及要使用的*度量标准*。#`cnn_learner`还有一个名为`pretrained`的参数，默认值为`True`（因此在这种情况下使用，即使我们没有指定），它将您模型中的权重设置为已经由专家训练过的值，以识别 130 万张照片中的一千个不同类别（使用著名的[*ImageNet*](http://www.image-net.org)数据集），即使用预训练模型。learn.fine_tune(1)#第六行告诉 fastai 如何适应模型，自动使用微调技术。\n不同类型的深度学习数据集和问题有各种类别，这里我们使用ImageDataLoaders。类名的第一部分通常是你拥有的数据类型，比如图像或文本。\n我们必须告诉 fastai 的另一个重要信息是如何从数据集中获取标签。计算机视觉数据集通常以标签作为文件名或路径的一部分进行结构化，最常见的是父文件夹名称。fastai 带有许多标准化的标记方法，以及编写自己的方法。在这里，我们告诉 fastai 使用我们刚刚定义的is_cat函数。\n最后，我们定义了我们需要的Transform。Transform包含在训练期间自动应用的代码；fastai 包含许多预定义的Transform，添加新的Transform就像创建一个 Python 函数一样简单。有两种类型：item_tfms应用于每个项目（在本例中，每个项目都被调整为 224 像素的正方形），而batch_tfms应用于一次处理一批项目的 GPU，因此它们特别快速（我们将在本书中看到许多这样的例子）。\n为什么是 224 像素？出于历史原因（旧的预训练模型需要这个确切的尺寸），但你几乎可以传入任何尺寸。如果增加尺寸，通常会得到更好的模型结果（因为它可以关注更多细节），但代价是速度和内存消耗；如果减小尺寸，则相反。\n为什么使用 CNN？这是创建计算机视觉模型的当前最先进方法。我们将在本书中学习有关 CNN 如何工作的所有知识。它们的结构受到人类视觉系统工作方式的启发。\n在 fastai 中有许多架构，我们将在本书中介绍（以及讨论如何创建您自己的架构）。然而，大多数情况下，选择架构并不是深度学习过程中非常重要的部分。这是学术界喜欢谈论的内容，但实际上您不太可能需要花费太多时间。有一些标准架构在大多数情况下都有效，而在这种情况下，我们使用的是一种称为ResNet的架构，我们将在本书中大量讨论；它对许多数据集和问题都既快速又准确。resnet34中的34指的是该架构变体中的层数（其他选项是18、50、101和152）。使用层数更多的架构模型训练时间更长，更容易过拟合（即在验证集上的准确率开始变差之前无法训练多少个时期）。另一方面，当使用更多数据时，它们可能会更准确。\n什么是度量标准？度量标准是一个函数，使用验证集来衡量模型预测的质量，并将在每个时期结束时打印出来。在这种情况下，我们使用error_rate，这是 fastai 提供的一个函数，它正是它所说的：告诉您验证集中有多少百分比的图像被错误分类。分类的另一个常见度量标准是accuracy（即1.0 - error_rate）。fastai 提供了许多其他度量标准，这将在本书中讨论。\n度量标准的概念可能会让您想起损失，但有一个重要区别。损失的整个目的是定义一个“性能度量”，训练系统可以使用它来自动更新权重。换句话说，损失的一个好选择是易于随机梯度下降使用的选择。但度量标准是为人类消费而定义的，因此一个好的度量标准是您易于理解的，并且尽可能接近您希望模型执行的任务。有时，您可能会决定损失函数是一个合适的度量标准，但这并不一定是情况。\n使用预训练模型时，cnn_learner将移除最后一层，因为该层始终是针对原始训练任务（即 ImageNet 数据集分类）专门定制的，并将其替换为一个或多个具有随机权重的新层，适合您正在处理的数据集的大小。模型的最后部分被称为头。\n这是深度学习的关键之处——确定如何适应模型的参数以使其解决您的问题。要适应一个模型，我们必须提供至少一条信息：每个图像查看多少次（称为时代数）。您选择的时代数将在很大程度上取决于您有多少时间可用，以及您发现在实践中适应模型需要多长时间。如果选择的数字太小，您可以随时稍后进行更多时代的训练。\n但为什么这种方法被称为fine_tune，而不是fit？fastai 确实有一个名为fit的方法，它确实适合一个模型（即，多次查看训练集中的图像，每次更新参数使预测越来越接近目标标签）。但在这种情况下，我们已经从一个预训练模型开始，并且我们不想丢弃它已经具有的所有这些功能。正如您将在本书中了解到的，有一些重要的技巧可以使预训练模型适应新数据集，这个过程称为微调。\n微调一种迁移学习技术，通过使用与预训练不同的任务进行额外时代的训练来更新预训练模型的参数。\n当您使用fine_tune方法时，fastai 将为您使用这些技巧。您可以设置一些参数（我们稍后会讨论），但在此处显示的默认形式中，它执行两个步骤：\n\n使用一个时代来适应模型的那些部分，以使新的随机头部能够正确地与您的数据集配合工作。\n\n在调用适合整个模型的方法时，请使用请求的时代数，更快地更新后面的层（特别是头部）的权重，而不是早期的层（正如我们将看到的，通常不需要对预训练权重进行太多更改）。\n\n\n模型的头部是新添加的部分，专门针对新数据集。一个时代是对数据集的一次完整遍历。在调用fit之后，每个时代后的结果都会被打印出来，显示时代编号，训练和验证集的损失（用于训练模型的“性能度量”），以及您请求的任何指标（在这种情况下是错误率）。\n因此，通过所有这些代码，我们的模型学会了仅仅通过标记的示例来识别猫和狗。但它是如何做到的呢？\n我们的图像识别器学到了什么在这个阶段，我们有一个工作良好的图像识别器，但我们不知道它在做什么！尽管许多人抱怨深度学习导致不可理解的“黑匣子”模型（即，可以提供预测但没有人能理解的东西），但事实并非如此。有大量研究表明如何深入检查深度学习模型并从中获得丰富的见解。话虽如此，各种机器学习模型（包括深度学习和传统统计模型）都可能难以完全理解，特别是考虑到它们在遇到与用于训练它们的数据非常不同的数据时的行为。我们将在本书中讨论这个问题。\n2013 年，博士生 Matt Zeiler 和他的导师 Rob Fergus 发表了《可视化和理解卷积网络》，展示了如何可视化模型每一层学到的神经网络权重。他们仔细分析了赢得 2012 年 ImageNet 比赛的模型，并利用这一分析大大改进了模型，使他们能够赢得 2013 年的比赛！图 1-10 是他们发表的第一层权重的图片。\n\n图 1-10。CNN 第一层的激活（由 Matthew D. Zeiler 和 Rob Fergus 提供）这张图片需要一些解释。对于每一层，具有浅灰色背景的图像部分显示了重建的权重，底部较大的部分显示了与每组权重最匹配的训练图像部分。对于第一层，我们可以看到模型发现了代表对角线、水平和垂直边缘以及各种梯度的权重。（请注意，对于每一层，只显示了部分特征；实际上，在所有层中有成千上万个特征。）\n这些是模型为计算机视觉学习的基本构建块。它们已经被神经科学家和计算机视觉研究人员广泛分析，结果表明，这些学习的构建块与人眼的基本视觉机制以及在深度学习之前开发的手工计算机视觉特征非常相似。下一层在图 1-11 中表示。\n\n图 1-11。CNN 第二层的激活（由 Matthew D. Zeiler 和 Rob Fergus 提供）对于第 2 层，模型找到的每个特征都有九个权重重建示例。我们可以看到模型已经学会创建寻找角、重复线条、圆圈和其他简单模式的特征检测器。这些是从第一层中开发的基本构建块构建的。对于每个特征，图片右侧显示了与这些特征最匹配的实际图像的小块。例如，第 2 行第 1 列中的特定模式与日落相关的梯度和纹理相匹配。\n图 1-12 显示了一篇论文中展示第 3 层特征重建结果的图片。\n\n图 1-12。CNN 第三层的激活（由 Matthew D. Zeiler 和 Rob Fergus 提供）通过观察图片右侧，您可以看到特征现在能够识别和匹配更高级的语义组件，如汽车车轮、文字和花瓣。利用这些组件，第 4 层和第 5 层可以识别更高级的概念，如图 1-13 所示。\n\n图 1-13。CNN 的第四和第五层的激活（由 Matthew D. Zeiler 和 Rob Fergus 提供）本文研究了一个名为AlexNet的旧模型，该模型只包含五层。自那时以来开发的网络可以有数百层 - 所以你可以想象这些模型开发的特征有多丰富！\n当我们早期微调我们的预训练模型时，我们调整了最后几层关注的内容（花朵、人类、动物），以专注于猫与狗问题。更一般地，我们可以将这样的预训练模型专门用于许多不同的任务。让我们看一些例子。\n图像识别器可以处理非图像任务其中举了一些将非图像处理任务的对象转换成图像之后再处理的例子，例如声波转换为声谱。\n术语回顾我们刚刚涵盖了很多信息，让我们简要回顾一下。表 1-3 提供了一个方便的词汇表。\n表 1-3. 深度学习词汇表\n\n\n\n\n术语\n意义\n\n\n\n\n标签\n我们试图预测的数据，比如“狗”或“猫”\n\n\n架构\n我们试图拟合的模型的  模板 ；即我们将输入数据和参数传递给的实际数学函数\n\n\n模型\n架构与特定一组参数的组合\n\n\n参数\n模型中改变任务的值，通过模型训练进行更新\n\n\n拟合\n更新模型的参数，使得使用输入数据的模型预测与目标标签匹配\n\n\n训练\n 拟合  的同义词\n\n\n预训练模型\n已经训练过的模型，通常使用大型数据集，并将进行微调\n\n\n微调\n为不同任务更新预训练模型\n\n\n纪元\n一次完整通过输入数据\n\n\n损失\n衡量模型好坏的指标，选择以驱动通过 SGD 进行训练\n\n\n指标\n使用验证集衡量模型好坏的测量标准，选择供人类消费\n\n\n验证集\n从训练中保留的一组数据，仅用于衡量模型好坏\n\n\n训练集\n用于拟合模型的数据；不包括验证集中的任何数据\n\n\n过拟合\n以使模型  记住  输入数据的特定特征而不是很好地泛化到训练期间未见的数据的方式训练模型\n\n\nCNN\n卷积神经网络；一种特别适用于计算机视觉任务的神经网络\n\n\n\n\n课后习题\n你需要这些来进行深度学习吗？\n\n很多数学 F\n\n很多数据 T\n\n很多昂贵的电脑 F\n\n一个博士学位 F\n\n\n\n列出深度学习现在是世界上最好的工具的五个领域。\n\n图像识别\n自然语言处理\n图像分割\n数据分析预测\n用户喜好推测\n\n\n第一个基于人工神经元原理的设备的名称是什么？\n\nMark 1 感知机\n\n\n根据同名书籍，分布式并行处理（PDP）的要求是什么？\n\n一组处理单元\n\n激活状态\n\n每个单元的输出函数\n\n单位之间的连接模式\n\n通过网络连接传播活动模式的传播规则\n\n将输入与单位的当前状态相结合以产生单位输出的激活规则\n\n通过经验修改连接模式的学习规则\n\n系统必须运行的环境\n\n\n\n\n\n是什么两个理论误解阻碍了神经网络领域的发展？\n使用多层设备可以解决这些限制\n单层无法学习一些简单但关键的数学函数（如异或）。\n\n\n\n\n打开一个笔记本并执行包含：1+1 的单元格。会发生什么？\n\n会output 2\n\n\n跟随本章笔记本的精简版本中的每个单元格。在执行每个单元格之前，猜测会发生什么。\n\n完成Jupyter Notebook 在线附录。\n\n为什么使用传统计算机程序来识别照片中的图像很困难？\n\n需要详细说明过程的每一个细微步骤。\n\n\n塞缪尔所说的“权重分配”是什么意思？\n\n即通过某种方式（如随机初始化、梯度下降优化等）为权重这种参数赋予初始值，并在训练过程中调整它们，使模型能更准确地拟合数据。\n\n\n在深度学习中，我们通常用什么术语来表示塞缪尔所说的“权重”？\n\n参数\n\n\n画一幅总结塞缪尔对机器学习模型看法的图片。\n\n为什么很难理解深度学习模型为什么会做出特定的预测？\n\n深度学习模型通过多层非线性变换提取抽象特征，导致决策过程高度复杂且缺乏直观解释性。\n\n\n展示了一个定理的名称，该定理表明神经网络可以解决任何数学问题并达到任何精度水平是什么？\n\n度量标准\n\n\n为了训练模型，您需要什么？\n\n大量数据 其中需要划分出训练集和数据集\n\n\n反馈循环如何影响预测性警务模型的推出？\n\n基于过去的逮捕地点创建了一个预测性执法模型。实际上，这并不是在预测犯罪，而是在预测逮捕，因此部分地只是反映了现有执法过程中的偏见。然后执法人员可能会使用该模型来决定在哪里集中他们的执法活动，导致这些地区的逮捕增加。这些额外逮捕的数据将被反馈回去重新训练未来版本的模型。\n\n这是一个正反馈循环：模型被使用得越多，数据就变得越有偏见，使模型变得更加有偏见，依此类推。\n\n反馈循环也可能在商业环境中造成问题。例如，视频推荐系统可能会偏向于推荐由视频最大观看者消费的内容（例如，阴谋论者和极端分子倾向于观看比平均水平更多的在线视频内容），导致这些用户增加他们的视频消费量，进而导致更多这类视频被推荐。我们将在第三章中更详细地讨论这个话题。\n\n\n\n我们在猫识别模型中总是需要使用 224×224 像素的图像吗？\n\n不需要这是旧版本的遗留问题，在现在像素越高效果就会越好但所需要的时间就会更多\n\n\n分类和回归之间有什么区别？\n分类预测离散类别（如是否垃圾邮件），回归预测连续数值（如房价）\n\n\n什么是验证集？什么是测试集？为什么我们需要它们？\n简单来说就是一组模型从未见过的数据用来验证模型的训练效果，防止少量数据过度训练后导致过拟合，使得模型仅仅只是记住训练集而已。\n验证集用于调参和模型选择，测试集用于最终评估模型泛化性能；两者分离以避免过拟合和确保评估客观性。\n\n\n如果不提供验证集，fastai 会怎么做？\n\n在valid_pct`默认设置比率fastai会将一定比率的训练集用作测试\n\n\n我们总是可以使用随机样本作为验证集吗？为什么或为什么不？\n\n不可以 一个随机子集是一个糟糕的选择（填补缺失太容易，且不代表你在生产中所需的）对于时间序列，选择数据的随机子集既太容易（你可以查看你试图预测的日期之前和之后的数据），又不代表大多数业务用例（在这些用例中，你使用历史数据构建模型以供将来使用）。\n\n\n什么是过拟合？举个例子。\n\n即使您的模型尚未完全记住所有数据，在训练的早期阶段可能已经记住了其中的某些部分。因此，您训练的时间越长，您在训练集上的准确性就会越好；验证集的准确性也会在一段时间内提高，但最终会开始变差，因为模型开始记住训练集而不是在数据中找到可泛化的潜在模式。\n\n\n什么是度量？它与损失有什么不同？\n度量标准是一个函数，使用验证集来衡量模型预测的质量，并将在每个时期结束时打印出来。在这种情况下，我们使用error_rate，这是 fastai 提供的一个函数，它正是它所说的：告诉您验证集中有多少百分比的图像被错误分类。分类的另一个常见度量标准是accuracy（即1.0 - error_rate）。fastai 提供了许多其他度量标准，这将在本书中讨论。\n性能的度量被称为损失。\n\n\n预训练模型如何帮助？\n预训练模型通过迁移学习大幅减少新任务所需数据和训练时间，同时提升模型性能。\n\n\n模型的“头”是什么？\n使用预训练模型时，cnn_learner将移除最后一层，因为该层始终是针对原始训练任务（即 ImageNet 数据集分类）专门定制的，并将其替换为一个或多个具有随机权重的新层，适合您正在处理的数据集的大小。模型的最后部分被称为头。\n\n\nCNN 的早期层找到了什么样的特征？后期层呢？\n\n\n\n图 1-10。CNN 第一层的激活（由 Matthew D. Zeiler 和 Rob Fergus 提供）这张图片需要一些解释。对于每一层，具有浅灰色背景的图像部分显示了重建的权重，底部较大的部分显示了与每组权重最匹配的训练图像部分。对于第一层，我们可以看到模型发现了代表对角线、水平和垂直边缘以及各种梯度的权重。（请注意，对于每一层，只显示了部分特征；实际上，在所有层中有成千上万个特征。）通过观察图片右侧，您可以看到特征现在能够识别和匹配更高级的语义组件，如汽车车轮、文字和花瓣。利用这些组件，第 4 层和第 5 层可以识别更高级的概念，如图 1-13 所示。\n\n图 1-13。CNN 的第四和第五层的激活（由 Matthew D. Zeiler 和 Rob Fergus 提供）\n图像模型仅对照片有用吗？\n\n否 你可以将相关的目标转换为图像后进行分析\n\n\n什么是架构？\n\n我们试图拟合的模型的  模板 ；即我们将输入数据和参数传递给的实际数学函数\n\n\n什么是分割？\n\n区分图片中的不同物体\n\n\ny_range 用于什么？什么时候需要它？\n预测的是一个连续数值，而不是一个类别时。告知我们的目标范围。\n\n\n什么是超参数？\n它们是关于参数的参数，因为它们是控制权重参数含义的高级选择。\n\n\n在组织中使用 AI 时避免失败的最佳方法是什么？\n真正理解测试和验证集以及它们的重要性进一步研究\n\n\n\n每章还有一个“进一步研究”部分，提出了一些在文本中没有完全回答的问题，或者给出了更高级的任务。这些问题的答案不在书的网站上；您需要自己进行研究！\n\n为什么 GPU 对深度学习有用？CPU 有什么不同之处，为什么对深度学习效果不佳？\n\n试着想出三个反馈循环可能影响机器学习使用的领域。看看是否能找到实践中发生这种情况的文档示例。\n\n\n","tags":["Machine Learning  Deep Learning"]}]